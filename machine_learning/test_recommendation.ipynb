{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "from ast import literal_eval as make_tuple\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "from pymongo import MongoClient\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn_deltatfidf import DeltaTfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import xgboost as xgb\n",
    "import sys\n",
    "sys.path.append('../machine_learning')\n",
    "import yelp_ml as yml\n",
    "reload(yml)\n",
    "from gensim import corpora, models, similarities, matutils\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import scrapped reviews\n",
    "dc_reviews = json.load(open(\"../Yelp_web_scrapper/dc_reviews.json\"))\n",
    "newyork_reviews = json.load(open(\"../Yelp_web_scrapper/newyork_reviews.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import word dictionaries\n",
    "lh_neg = open('../input/negative-words.txt', 'r').read()\n",
    "lh_neg = lh_neg.split('\\n')\n",
    "lh_pos = open('../input/positive-words.txt', 'r').read()\n",
    "lh_pos = lh_pos.split('\\n')\n",
    "users = json.load(open(\"cleaned_large_user_dictionary.json\"))\n",
    "word_list = list(set(lh_pos + lh_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "large_user_number = 178"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "\n",
      "100%|██████████| 1/1 [13:31<00:00, 811.11s/it]\u001b[A\n",
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "#####Pull restaurant data for a given user\n",
    "ip = '54.175.170.119'\n",
    "conn = MongoClient(ip, 27017)\n",
    "conn.database_names()\n",
    "db = conn.get_database('cleaned_data')\n",
    "reviews = db.get_collection('restaurant_reviews')\n",
    "\n",
    "for j in tqdm.tqdm(range(large_user_number, large_user_number+1)):\n",
    "    user_df = yml.make_user_df(users[users.keys()[j]])\n",
    "    business_ids = list(set(user_df['biz_id']))\n",
    "#     restreview = {}\n",
    "\n",
    "#     for i in range(0, len(business_ids)):\n",
    "#         rlist = []\n",
    "#         for obj in reviews.find({'business_id':business_ids[i]}):\n",
    "#             rlist.append(obj)\n",
    "#         restreview[business_ids[i]] = rlist\n",
    "    restaurant_df = yml.make_biz_df(users.keys()[j], restreview)\n",
    "    \n",
    "    #Create a training and test sample from the user reviewed restaurants\n",
    "    split_samp = .25\n",
    "    len_random = int(len(business_ids) * split_samp)\n",
    "    test_set = random.sample(business_ids, len_random)\n",
    "    training_set = [x for x in business_ids if x not in test_set]\n",
    "    sub_train_reviews, train_labels, train_reviews, train_ratings = [], [], [], []\n",
    "\n",
    "    #Create a list of training reviews and training ratings\n",
    "    for rest_id in training_set:\n",
    "        train_reviews.append((user_df[user_df['biz_id'] == rest_id]['review_text'].iloc[0],\n",
    "                                 user_df[user_df['biz_id'] == rest_id]['rating'].iloc[0]))\n",
    "\n",
    "    #Create an even sample s.t. len(positive_reviews) = len(negative_reviews)\n",
    "    sample_size = min(len([x[1] for x in train_reviews if x[1] < 4]),\n",
    "                          len([x[1] for x in train_reviews if x[1] >= 4]))\n",
    "    \n",
    "    bad_reviews = [x for x in train_reviews if x[1] < 4]\n",
    "    good_reviews = [x for x in train_reviews if x[1] >= 4]\n",
    "\n",
    "    for L in range(0, int(float(sample_size)/float(2))):\n",
    "        sub_train_reviews.append(bad_reviews[L][0])\n",
    "        sub_train_reviews.append(good_reviews[L][0])\n",
    "        train_labels.append(bad_reviews[L][1])\n",
    "        train_labels.append(good_reviews[L][1])\n",
    "        \n",
    "    #Make the train labels binary\n",
    "    train_labels = [1 if x >=4 else 0 for x in train_labels]\n",
    "    \n",
    "    #Fit LSI model and return number of LSI topics\n",
    "    lsi, topics, dictionary = yml.fit_lsi(sub_train_reviews)\n",
    "\n",
    "    #Make a FeatureUnion object with the desired features then fit to train reviews\n",
    "    test_results = {}\n",
    "    feature_selection = {\"sent_tf\":(True, True, False), \n",
    "                         \"sent\": (True,False,False),\n",
    "                         \"tf_lda\": (False,True,True), \n",
    "                         \"all\": (True, True, True)}\n",
    "\n",
    "    for feature in feature_selection.keys():\n",
    "        #Make a FeatureUnion object with the desired features then fit to train reviews\n",
    "        comb_features = yml.make_featureunion(sent_percent=feature_selection[feature][0], \n",
    "                                              tf = feature_selection[feature][1], \n",
    "                                              lda = feature_selection[feature][2])\n",
    "        \n",
    "        delta_vect = None\n",
    "        comb_features.fit(sub_train_reviews)\n",
    "        train_features = comb_features.transform(sub_train_reviews)\n",
    "        train_lsi = yml.get_lsi_features(sub_train_reviews, lsi, topics, dictionary)\n",
    "        train_features = sparse.hstack((train_features, train_lsi))\n",
    "        train_features = train_features.todense()\n",
    "\n",
    "        #Fit LSI model and return number of LSI topics\n",
    "        lsi, topics, dictionary = yml.fit_lsi(sub_train_reviews)\n",
    "        \n",
    "        #fit each model in turn \n",
    "        model_runs = {\"svm\": (True, False, False),\n",
    "                      \"rf\": (False, True, False), \n",
    "                      \"naive_bayes\": (False, False, True)}\n",
    "\n",
    "        for model_run in model_runs.keys():\n",
    "            clf = yml.fit_model(train_features, train_labels, svm_clf = model_runs[model_run][0], \n",
    "                            RandomForest = model_runs[model_run][1], \n",
    "                                nb = model_runs[model_run][2])\n",
    "            threshold = 0.7\n",
    "            error = yml.test_user_set(test_set, clf, restaurant_df, user_df, comb_features, \n",
    "                                      threshold, lsi, topics, dictionary, delta_vect)\n",
    "            test_results[(feature, model_run)] = (yml.get_log_loss(error), \n",
    "                                            yml.get_accuracy_score(error), \n",
    "                                            yml.get_precision_score(error))\n",
    "    \n",
    "    string_keys_dict = {}\n",
    "    for key in test_results.keys():\n",
    "        string_keys_dict[str(key)] = test_results[key]\n",
    "            \n",
    "with open('test_results.json', 'wb') as fp:\n",
    "    json.dump(string_keys_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_results = string_keys_dict.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "100%|██████████| 1/1 [00:38<00:00, 38.65s/it]\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "#Make a Recommendation\n",
    "#########################\n",
    "\n",
    "#Get feature and model combination that yields the highest precision\n",
    "for key in test_results.keys():\n",
    "    feat_model = make_tuple(key)\n",
    "    if not top_results:\n",
    "        top_results = [(feat_model,test_results[key][2])]\n",
    "    else:\n",
    "        if test_results[key][2] > top_results[0][1]:\n",
    "            top_results.pop()\n",
    "            top_results = [(feat_model, test_results[key][2])]\n",
    "feat_result = top_results[0][0][0]\n",
    "model_result = top_results[0][0][1]\n",
    "\n",
    "for j in tqdm.tqdm(range(large_user_number, large_user_number+1)):\n",
    "    user_df = yml.make_user_df(users[users.keys()[j]])\n",
    "    business_ids = list(set(user_df['biz_id']))\n",
    "\n",
    "    #Create a list of training reviews and training ratings\n",
    "    for rest_id in business_ids:\n",
    "        train_reviews.append((user_df[user_df['biz_id'] == rest_id]['review_text'].iloc[0],\n",
    "                                 user_df[user_df['biz_id'] == rest_id]['rating'].iloc[0]))\n",
    "\n",
    "    #Create an even sample s.t. len(positive_reviews) = len(negative_reviews)\n",
    "    sample_size = min(len([x[1] for x in train_reviews if x[1] < 4]),\n",
    "                          len([x[1] for x in train_reviews if x[1] >= 4]))\n",
    "    \n",
    "    bad_reviews = [x for x in train_reviews if x[1] < 4]\n",
    "    good_reviews = [x for x in train_reviews if x[1] >= 4]\n",
    "    \n",
    "    train_labels = []\n",
    "    sub_train_reviews = []\n",
    "    for L in range(0, int(float(sample_size)/float(2))):\n",
    "        sub_train_reviews.append(bad_reviews[L][0])\n",
    "        sub_train_reviews.append(good_reviews[L][0])\n",
    "        train_labels.append(bad_reviews[L][1])\n",
    "        train_labels.append(good_reviews[L][1])\n",
    "        \n",
    "    #Make the train labels binary\n",
    "    train_labels = [1 if x >=4 else 0 for x in train_labels]\n",
    "    \n",
    "    #Fit LSI model and return number of LSI topics\n",
    "    lsi, topics, dictionary = yml.fit_lsi(sub_train_reviews)\n",
    "\n",
    "    #Make a FeatureUnion object with the desired features then fit to train reviews\n",
    "    feature_selection = {\"sent_tf\":(True, True, False), \n",
    "                         \"sent\": (True,False,False),\n",
    "                         \"tf_lda\": (False,True,True), \n",
    "                         \"all\": (True, True, True)}\n",
    "    top_feature = feature_selection['all']\n",
    "    \n",
    "    comb_features = yml.make_featureunion(sent_percent=top_feature[0], \n",
    "                                          tf = top_feature[1], \n",
    "                                          lda = top_feature[2])\n",
    "        \n",
    "    comb_features.fit(sub_train_reviews)\n",
    "    train_features = comb_features.transform(sub_train_reviews)\n",
    "    train_lsi = yml.get_lsi_features(sub_train_reviews, lsi, topics, dictionary)\n",
    "    train_features = sparse.hstack((train_features, train_lsi))\n",
    "    train_features = train_features.todense()\n",
    "\n",
    "    #Fit LSI model and return number of LSI topics\n",
    "    lsi, topics, dictionary = yml.fit_lsi(sub_train_reviews)\n",
    "        \n",
    "    #Get the top performing model and fit using that model\n",
    "    model_runs = {\"svm\": (True, False, False),\n",
    "                  \"rf\": (False, True, False), \n",
    "                  \"naive_bayes\": (False, False, True)}\n",
    "    top_model = model_runs['svm']\n",
    "    clf = yml.fit_model(train_features, train_labels, svm_clf = top_model[0], \n",
    "                RandomForest = top_model[1], \n",
    "                    nb = top_model[2])\n",
    "\n",
    "    threshold = 0.7\n",
    "    user_results = yml.make_rec(dc_reviews, clf, threshold, comb_features, \n",
    "                                lsi, topics, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################################################################\n",
    "#Collect the results into a list of tuples, then select the top\n",
    "#5 most confident good recs and top 5 most confident bad recs\n",
    "################################################################\n",
    "\n",
    "tuple_results = []\n",
    "for result in user_results:\n",
    "    tuple_results.append((result[1], result[2], result[3]))\n",
    "    \n",
    "#Sort the list of tuples by predicition confidence\n",
    "tuple_results = sorted(tuple_results, key=lambda tup: tup[1])\n",
    "top_5 = tuple_results[-5:]\n",
    "bottom_5 = tuple_results[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'/biz/flight-wine-bar-washington', 0.90000000000000002, 1),\n",
       " (u'/biz/convivial-washington', 0.90000000000000002, 1),\n",
       " (u'/biz/little-serow-washington', 0.90000000000000002, 1),\n",
       " (u'/biz/beef-n-bread-washington', 0.90000000000000002, 1),\n",
       " (u'/biz/himitsu-washington', 0.94999999999999996, 1)]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the top 5 restaurants\n",
    "top_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'/biz/kabob-square-washington', 0.0, 0),\n",
       " (u'/biz/honeygrow-washington', 0.10000000000000001, 0),\n",
       " (u'/biz/ten-tigers-parlour-washington', 0.10000000000000001, 0),\n",
       " (u'/biz/tonton-chicken-washington', 0.14999999999999999, 0),\n",
       " (u'/biz/potters-house-washington', 0.14999999999999999, 0)]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the bottom 5 restaurants\n",
    "bottom_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>biz_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29XtLRA0y7Nfi4eZF-ZI4A</td>\n",
       "      <td>4</td>\n",
       "      <td>sad to report lose to this area but CLOSED at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9z3fqEeQXfxdF_sqkpPsSA</td>\n",
       "      <td>2</td>\n",
       "      <td>The TRUTH is Freaky chemicals ARE ADDED to for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I2LcbNXGsMb6zxh4-gmVHw</td>\n",
       "      <td>3</td>\n",
       "      <td>Our Tuna Spring Rolls were very pretty and lar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Slpd4sRuICx1cy2Etb-7ig</td>\n",
       "      <td>2</td>\n",
       "      <td>I was hesitant about trying this buffet becaus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cKgUCzMGuRgkbKXUsgeXUw</td>\n",
       "      <td>2</td>\n",
       "      <td>I knew that going to a new restaurant on openi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   biz_id  rating  \\\n",
       "0  29XtLRA0y7Nfi4eZF-ZI4A       4   \n",
       "1  9z3fqEeQXfxdF_sqkpPsSA       2   \n",
       "2  I2LcbNXGsMb6zxh4-gmVHw       3   \n",
       "3  Slpd4sRuICx1cy2Etb-7ig       2   \n",
       "4  cKgUCzMGuRgkbKXUsgeXUw       2   \n",
       "\n",
       "                                         review_text  \n",
       "0  sad to report lose to this area but CLOSED at ...  \n",
       "1  The TRUTH is Freaky chemicals ARE ADDED to for...  \n",
       "2  Our Tuna Spring Rolls were very pretty and lar...  \n",
       "3  I was hesitant about trying this buffet becaus...  \n",
       "4  I knew that going to a new restaurant on openi...  "
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#user_df contains all of the user's reviews, with one column of restaurants,\n",
    "#one column of the user's ratings, and one column with the user's reviews\n",
    "user_df.head()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
