{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "from ast import literal_eval as make_tuple\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "from pymongo import MongoClient\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn_deltatfidf import DeltaTfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import xgboost as xgb\n",
    "import sys\n",
    "sys.path.append('../machine_learning')\n",
    "import yelp_ml as yml\n",
    "reload(yml)\n",
    "from gensim import corpora, models, similarities, matutils\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import scrapped reviews\n",
    "dc_reviews = json.load(open(\"../Yelp_web_scrapper/dc_reviews.json\"))\n",
    "newyork_reviews = json.load(open(\"../Yelp_web_scrapper/newyork_reviews.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import word dictionaries\n",
    "lh_neg = open('../input/negative-words.txt', 'r').read()\n",
    "lh_neg = lh_neg.split('\\n')\n",
    "lh_pos = open('../input/positive-words.txt', 'r').read()\n",
    "lh_pos = lh_pos.split('\\n')\n",
    "users = json.load(open(\"cleaned_large_user_dictionary.json\"))\n",
    "word_list = list(set(lh_pos + lh_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "\n",
      "  3%|▎         | 1/30 [36:27<17:37:24, 2187.74s/it]\u001b[A/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "\n",
      "  7%|▋         | 2/30 [49:57<13:48:03, 1774.40s/it]\u001b[A/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "\n",
      " 10%|█         | 3/30 [1:11:33<12:13:53, 1630.87s/it]\u001b[A"
     ]
    },
    {
     "ename": "ServerSelectionTimeoutError",
     "evalue": "54.175.170.119:27017: [Errno 51] Network is unreachable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mServerSelectionTimeoutError\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-161-2f9c55235517>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbusiness_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mrlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'business_id'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbusiness_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m                     \u001b[0mrlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0mrestreview\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbusiness_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrlist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/pymongo/cursor.pyc\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0m_db\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__collection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_refresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__manipulate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m                 return _db._fix_outgoing(self.__data.popleft(),\n",
      "\u001b[0;32m/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/pymongo/cursor.pyc\u001b[0m in \u001b[0;36m_refresh\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1010\u001b[0m                                        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__limit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                                        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1012\u001b[0;31m                                        self.__read_concern))\n\u001b[0m\u001b[1;32m   1013\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__id\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__killed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/pymongo/cursor.pyc\u001b[0m in \u001b[0;36m__send_message\u001b[0;34m(self, operation)\u001b[0m\n\u001b[1;32m    848\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m                 response = client._send_message_with_response(operation,\n\u001b[0;32m--> 850\u001b[0;31m                                                               **kwargs)\n\u001b[0m\u001b[1;32m    851\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__address\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__exhaust\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/pymongo/mongo_client.pyc\u001b[0m in \u001b[0;36m_send_message_with_response\u001b[0;34m(self, operation, read_preference, exhaust, address)\u001b[0m\n\u001b[1;32m    825\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m             \u001b[0mselector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_preference\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mwritable_server_selector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m             \u001b[0mserver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0;31m# A _Query's slaveOk bit is already set for queries with non-primary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/pymongo/topology.pyc\u001b[0m in \u001b[0;36mselect_server\u001b[0;34m(self, selector, server_selection_timeout, address)\u001b[0m\n\u001b[1;32m    208\u001b[0m         return random.choice(self.select_servers(selector,\n\u001b[1;32m    209\u001b[0m                                                  \u001b[0mserver_selection_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m                                                  address))\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     def select_server_by_address(self, address,\n",
      "\u001b[0;32m/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/pymongo/topology.pyc\u001b[0m in \u001b[0;36mselect_servers\u001b[0;34m(self, selector, server_selection_timeout, address)\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mserver_timeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnow\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                     raise ServerSelectionTimeoutError(\n\u001b[0;32m--> 186\u001b[0;31m                         self._error_message(selector))\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_opened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mServerSelectionTimeoutError\u001b[0m: 54.175.170.119:27017: [Errno 51] Network is unreachable"
     ]
    }
   ],
   "source": [
    "#####Pull restaurant data for a given user\n",
    "ip = '54.175.170.119'\n",
    "conn = MongoClient(ip, 27017)\n",
    "conn.database_names()\n",
    "db = conn.get_database('cleaned_data')\n",
    "reviews = db.get_collection('restaurant_reviews')\n",
    "string_keys_dict = {}\n",
    "for j in tqdm.tqdm(range(0, 30)):\n",
    "    test_results = {}\n",
    "    user_df = yml.make_user_df(users[users.keys()[j]])\n",
    "    \n",
    "    if len([x for x in user_df['rating'] if x < 4]) < 20:\n",
    "        string_keys_dict[str(users.keys()[j])] = test_results\n",
    "        continue\n",
    "    else:\n",
    "        business_ids = list(set(user_df['biz_id']))\n",
    "        restreview = {}\n",
    "        \n",
    "        #Create a training and test sample from the user reviewed restaurants\n",
    "        split_samp = .25\n",
    "        len_random = int(len(business_ids) * split_samp)\n",
    "        test_set = random.sample(business_ids, len_random)\n",
    "        training_set = [x for x in business_ids if x not in test_set]\n",
    "        sub_train_reviews, train_labels, train_reviews, train_ratings = [], [], [], []\n",
    "\n",
    "        #Create a list of training reviews and training ratings\n",
    "        for rest_id in training_set:\n",
    "            train_reviews.append((user_df[user_df['biz_id'] == rest_id]['review_text'].iloc[0],\n",
    "                                     user_df[user_df['biz_id'] == rest_id]['rating'].iloc[0]))\n",
    "\n",
    "        #Create an even sample s.t. len(positive_reviews) = len(negative_reviews)\n",
    "        sample_size = min(len([x[1] for x in train_reviews if x[1] < 4]),\n",
    "                              len([x[1] for x in train_reviews if x[1] >= 4]))\n",
    "\n",
    "        bad_reviews = [x for x in train_reviews if x[1] < 4]\n",
    "        good_reviews = [x for x in train_reviews if x[1] >= 4]\n",
    "\n",
    "        for L in range(0, int(float(sample_size)/float(2))):\n",
    "            sub_train_reviews.append(bad_reviews[L][0])\n",
    "            sub_train_reviews.append(good_reviews[L][0])\n",
    "            train_labels.append(bad_reviews[L][1])\n",
    "            train_labels.append(good_reviews[L][1])\n",
    "\n",
    "        #Make the train labels binary\n",
    "        train_labels = [1 if x >=4 else 0 for x in train_labels]\n",
    "        \n",
    "        if not sub_train_reviews:\n",
    "            string_keys_dict[str(users.keys()[j])] = test_results\n",
    "            continue\n",
    "        else:\n",
    "            for i in range(0, len(business_ids)):\n",
    "                rlist = []\n",
    "                for obj in reviews.find({'business_id':business_ids[i]}):\n",
    "                    rlist.append(obj)\n",
    "                restreview[business_ids[i]] = rlist\n",
    "\n",
    "            restaurant_df = yml.make_biz_df(users.keys()[j], restreview)\n",
    "\n",
    "            #Make a FeatureUnion object with the desired features then fit to train reviews\n",
    "            feature_selection = {\"sent_tf\":(True, True, False), \n",
    "                                 \"sent\": (True,False,False),\n",
    "                                 \"tf_lda\": (False,True,True), \n",
    "                                 \"all\": (True, True, True)}\n",
    "\n",
    "            for feature in feature_selection.keys():\n",
    "                #Make a FeatureUnion object with the desired features then fit to train reviews\n",
    "                comb_features = yml.make_featureunion(sent_percent=feature_selection[feature][0], \n",
    "                                                      tf = feature_selection[feature][1], \n",
    "                                                      lda = feature_selection[feature][2])\n",
    "\n",
    "                delta_vect = None\n",
    "                comb_features.fit(sub_train_reviews)\n",
    "                train_features = comb_features.transform(sub_train_reviews)\n",
    "\n",
    "                #Fit LSI model and return number of LSI topics\n",
    "                lsi, topics, dictionary = yml.fit_lsi(sub_train_reviews)\n",
    "                train_lsi = yml.get_lsi_features(sub_train_reviews, lsi, topics, dictionary)\n",
    "\n",
    "                #Stack the LSI and combined features together\n",
    "                train_features = sparse.hstack((train_features, train_lsi))\n",
    "                train_features = train_features.todense()\n",
    "\n",
    "                #fit each model in turn \n",
    "                model_runs = {\"svm\": (True, False, False),\n",
    "                              \"rf\": (False, True, False), \n",
    "                              \"naive_bayes\": (False, False, True)}\n",
    "\n",
    "                for model_run in model_runs.keys():\n",
    "                    clf = yml.fit_model(train_features, train_labels, svm_clf = model_runs[model_run][0], \n",
    "                                    RandomForest = model_runs[model_run][1], \n",
    "                                        nb = model_runs[model_run][2])\n",
    "                    threshold = 0.7\n",
    "                    error = yml.test_user_set(test_set, clf, restaurant_df, user_df, comb_features, \n",
    "                                              threshold, lsi, topics, dictionary, delta_vect)\n",
    "                    test_results[str((feature, model_run))] = (yml.get_log_loss(error), \n",
    "                                                    yml.get_accuracy_score(error), \n",
    "                                                    yml.get_precision_score(error))\n",
    "                \n",
    "    string_keys_dict[str(users.keys()[j])] = test_results\n",
    "            \n",
    "with open('test_results.json', 'wb') as fp:\n",
    "    json.dump(string_keys_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "100%|██████████| 1/1 [00:37<00:00, 37.79s/it]\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "#Make a Recommendation\n",
    "#########################\n",
    "top_results = []\n",
    "#Get feature and model combination that yields the highest precision\n",
    "for key in test_results.keys():\n",
    "    feat_model = make_tuple(key)\n",
    "    if not top_results:\n",
    "        top_results = [(feat_model,test_results[key][2])]\n",
    "    else:\n",
    "        if test_results[key][2] > top_results[0][1]:\n",
    "            top_results.pop()\n",
    "            top_results = [(feat_model, test_results[key][2])]\n",
    "feat_result = top_results[0][0][0]\n",
    "model_result = top_results[0][0][1]\n",
    "\n",
    "for j in tqdm.tqdm(range(156, 157)):\n",
    "    user_df = yml.make_user_df(users[users.keys()[j]])\n",
    "    business_ids = list(set(user_df['biz_id']))\n",
    "\n",
    "    #Create a list of training reviews and training ratings\n",
    "    for rest_id in business_ids:\n",
    "        train_reviews.append((user_df[user_df['biz_id'] == rest_id]['review_text'].iloc[0],\n",
    "                                 user_df[user_df['biz_id'] == rest_id]['rating'].iloc[0]))\n",
    "\n",
    "    #Create an even sample s.t. len(positive_reviews) = len(negative_reviews)\n",
    "    sample_size = min(len([x[1] for x in train_reviews if x[1] < 4]),\n",
    "                          len([x[1] for x in train_reviews if x[1] >= 4]))\n",
    "    \n",
    "    bad_reviews = [x for x in train_reviews if x[1] < 4]\n",
    "    good_reviews = [x for x in train_reviews if x[1] >= 4]\n",
    "    \n",
    "    train_labels = []\n",
    "    sub_train_reviews = []\n",
    "    for L in range(0, int(float(sample_size)/float(2))):\n",
    "        sub_train_reviews.append(bad_reviews[L][0])\n",
    "        sub_train_reviews.append(good_reviews[L][0])\n",
    "        train_labels.append(bad_reviews[L][1])\n",
    "        train_labels.append(good_reviews[L][1])\n",
    "        \n",
    "    #Make the train labels binary\n",
    "    train_labels = [1 if x >=4 else 0 for x in train_labels]\n",
    "    \n",
    "    #Fit LSI model and return number of LSI topics\n",
    "    lsi, topics, dictionary = yml.fit_lsi(sub_train_reviews)\n",
    "\n",
    "    #Make a FeatureUnion object with the desired features then fit to train reviews\n",
    "    feature_selection = {\"sent_tf\":(True, True, False), \n",
    "                         \"sent\": (True,False,False),\n",
    "                         \"tf_lda\": (False,True,True), \n",
    "                         \"all\": (True, True, True)}\n",
    "    top_feature = feature_selection['all']\n",
    "    \n",
    "    comb_features = yml.make_featureunion(sent_percent=top_feature[0], \n",
    "                                          tf = top_feature[1], \n",
    "                                          lda = top_feature[2])\n",
    "        \n",
    "    comb_features.fit(sub_train_reviews)\n",
    "    train_features = comb_features.transform(sub_train_reviews)\n",
    "    train_lsi = yml.get_lsi_features(sub_train_reviews, lsi, topics, dictionary)\n",
    "    train_features = sparse.hstack((train_features, train_lsi))\n",
    "    train_features = train_features.todense()\n",
    "\n",
    "    #Fit LSI model and return number of LSI topics\n",
    "    lsi, topics, dictionary = yml.fit_lsi(sub_train_reviews)\n",
    "        \n",
    "    #Get the top performing model and fit using that model\n",
    "    model_runs = {\"svm\": (True, False, False),\n",
    "                  \"rf\": (False, True, False), \n",
    "                  \"naive_bayes\": (False, False, True)}\n",
    "    top_model = model_runs['svm']\n",
    "    clf = yml.fit_model(train_features, train_labels, svm_clf = top_model[0], \n",
    "                RandomForest = top_model[1], \n",
    "                    nb = top_model[2])\n",
    "\n",
    "    threshold = 0.7\n",
    "    user_results = yml.make_rec(dc_reviews, clf, threshold, comb_features, \n",
    "                                lsi, topics, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################################################################\n",
    "#Collect the results into a list of tuples, then select the top\n",
    "#5 most confident good recs and top 5 most confident bad recs\n",
    "################################################################\n",
    "tuple_results = []\n",
    "for result in user_results:\n",
    "    tuple_results.append((result[1], result[2], result[3]))\n",
    "    \n",
    "#Sort the list of tuples by predicition confidence\n",
    "tuple_results = sorted(tuple_results, key=lambda tup: tup[1])\n",
    "top_5 = tuple_results[-5:]\n",
    "bottom_5 = tuple_results[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'/biz/kingbird-washington', 0.94999999999999996, 1),\n",
       " (u'/biz/tortino-restaurant-washington', 0.94999999999999996, 1),\n",
       " (u'/biz/ristorante-la-perla-of-washington-washington-3',\n",
       "  0.94999999999999996,\n",
       "  1),\n",
       " (u'/biz/seasons-restaurant-washington', 1.0, 1),\n",
       " (u'/biz/marcels-by-robert-wiedmaier-washington', 1.0, 1)]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the top 5 restaurants\n",
    "top_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'/biz/bozzellis-washington', 0.050000000000000003, 0),\n",
       " (u'/biz/korean-signature-bibimbap-washington', 0.10000000000000001, 0),\n",
       " (u'/biz/and-pizza-washington-11', 0.10000000000000001, 0),\n",
       " (u'/biz/flippin-pizza-washington-4', 0.10000000000000001, 0),\n",
       " (u'/biz/cornerstone-cafe-washington', 0.14999999999999999, 0)]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the bottom 5 restaurants\n",
    "bottom_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>biz_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM4ivx69oX71Dsveu26Tmw</td>\n",
       "      <td>4</td>\n",
       "      <td>So Wednesday evening I needed milk and cat foo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2BbFeotL85cIaBjSq1SWiA</td>\n",
       "      <td>4</td>\n",
       "      <td>I am getting to this a bit late as I was there...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KRsANC7TzP97KMFRA1JqiQ</td>\n",
       "      <td>4</td>\n",
       "      <td>So I wasnt sure where I wanted to eat lunch to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3TnNC-AMuQ4upCtcgtU49w</td>\n",
       "      <td>3</td>\n",
       "      <td>I had a Groupon for this place how many review...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5Je2-6KDxPQJZdItfo1ngg</td>\n",
       "      <td>4</td>\n",
       "      <td>For my money the best of the 3 or 4 Asian buff...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   biz_id  rating  \\\n",
       "0  BM4ivx69oX71Dsveu26Tmw       4   \n",
       "1  2BbFeotL85cIaBjSq1SWiA       4   \n",
       "2  KRsANC7TzP97KMFRA1JqiQ       4   \n",
       "3  3TnNC-AMuQ4upCtcgtU49w       3   \n",
       "4  5Je2-6KDxPQJZdItfo1ngg       4   \n",
       "\n",
       "                                         review_text  \n",
       "0  So Wednesday evening I needed milk and cat foo...  \n",
       "1  I am getting to this a bit late as I was there...  \n",
       "2  So I wasnt sure where I wanted to eat lunch to...  \n",
       "3  I had a Groupon for this place how many review...  \n",
       "4  For my money the best of the 3 or 4 Asian buff...  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#user_df contains all of the user's reviews, with one column of restaurants,\n",
    "#one column of the user's ratings, and one column with the user's reviews\n",
    "user_df = yml.make_user_df(users[users.keys()[j]])\n",
    "user_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "sandwich got potatoes croissant cup\n",
      "Topic 1:\n",
      "courses wasnt ibus selections peopleservice\n",
      "Topic 2:\n",
      "touch organized wonder table companions\n",
      "Topic 3:\n",
      "special culinary realizes graduation 51\n",
      "Topic 4:\n",
      "outlets years anthem indoors smoked\n",
      "Topic 5:\n",
      "club loved curbside carne tour\n",
      "Topic 6:\n",
      "dog dogs hot suggest trailer\n",
      "Topic 7:\n",
      "5090 hugely bags twitter potatos\n",
      "Topic 8:\n",
      "alexander rooms member dept definite\n",
      "Topic 9:\n",
      "spring great day tacos good\n",
      "Topic 10:\n",
      "structure cheese rice attendants good\n",
      "Topic 11:\n",
      "farm uye gravy setting curry\n",
      "Topic 12:\n",
      "place good food lunch time\n",
      "Topic 13:\n",
      "dog hot dill relish chicago\n",
      "Topic 14:\n",
      "corner steady got sales proved\n",
      "Topic 15:\n",
      "donut flour regularity preparation away\n",
      "Topic 16:\n",
      "sum plaza dim sandwich explore\n",
      "Topic 17:\n",
      "wasnt busing new recipes location\n",
      "Topic 18:\n",
      "lennys outposts nicest swiss mushroom\n",
      "Topic 19:\n",
      "fish piece stopped basis fine\n",
      "Topic 20:\n",
      "pao hourappetizers grumpy wok craft\n",
      "Topic 21:\n",
      "conference covered room pea ok\n",
      "Topic 22:\n",
      "cohesive periods forgetting attentiveness interspersed\n",
      "Topic 23:\n",
      "customer starbucks considered batches mens\n",
      "Topic 24:\n",
      "everyday disintegrated upscale nick inattentive\n",
      "Topic 25:\n",
      "food chickfila fish consistent reasons\n",
      "Topic 26:\n",
      "doughnut reasonably differences mexico cheese\n",
      "Topic 27:\n",
      "fell selection taking judge labeled\n",
      "Topic 28:\n",
      "decaf palace justify quantity gaps\n",
      "Topic 29:\n",
      "ham breakfast biscuit location sausage\n",
      "Topic 30:\n",
      "fastcasual place pizza son 40\n",
      "Topic 31:\n",
      "jumped join played disaster to13\n",
      "Topic 32:\n",
      "reflected didnt reopened caught surprise\n",
      "Topic 33:\n",
      "regular tvs area main available\n",
      "Topic 34:\n",
      "existing group pretty entree folks\n",
      "Topic 35:\n",
      "parts old separation canadian detract\n",
      "Topic 36:\n",
      "pairs seat times happen bump\n",
      "Topic 37:\n",
      "haircut dozen expensive burritos yes\n",
      "Topic 38:\n",
      "eve awkward candle conditioned ray\n",
      "Topic 39:\n",
      "sambos bargain pea 08 eyed\n",
      "Topic 40:\n",
      "predictable graded innout kill mood\n",
      "Topic 41:\n",
      "3rd teppan talkative adventurous flowed\n",
      "Topic 42:\n",
      "reasonable mini goods hostess convert\n",
      "Topic 43:\n",
      "creamed chipped convenient comfortable daily\n",
      "Topic 44:\n",
      "lounge timely act enjoy music\n",
      "Topic 45:\n",
      "hair stores expected mushroom chopsticks\n",
      "Topic 46:\n",
      "sandwich built yelped teeth shaved\n",
      "Topic 47:\n",
      "wings knots followed zepellies shattering\n",
      "Topic 48:\n",
      "reviewed julia fundraiser decades mcmuffins\n",
      "Topic 49:\n",
      "rest bloody led number spots\n"
     ]
    }
   ],
   "source": [
    "#View the top words in the LDA representation\n",
    "vectorizer = TfidfVectorizer(stop_words='english', ngram_range = (1,1))\n",
    "tf = vectorizer.fit_transform(sub_train_reviews)\n",
    "lda_fit = LatentDirichletAllocation(n_topics=50).fit(tf)\n",
    "\n",
    "#Display top words in each topic                     \n",
    "no_top_words = 5\n",
    "tf_feature_names = vectorizer.get_feature_names()\n",
    "yml.display_topics(lda_fit, tf_feature_names, no_top_words)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
