{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "from ast import literal_eval as make_tuple\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "from pymongo import MongoClient\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn_deltatfidf import DeltaTfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import xgboost as xgb\n",
    "import sys\n",
    "sys.path.append('../machine_learning')\n",
    "import yelp_ml as yml\n",
    "reload(yml)\n",
    "from gensim import corpora, models, similarities, matutils\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import scrapped reviews\n",
    "dc_reviews = json.load(open(\"../Yelp_web_scrapper/dc_reviews.json\"))\n",
    "newyork_reviews = json.load(open(\"../Yelp_web_scrapper/newyork_reviews.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import word dictionaries\n",
    "lh_neg = open('../input/negative-words.txt', 'r').read()\n",
    "lh_neg = lh_neg.split('\\n')\n",
    "lh_pos = open('../input/positive-words.txt', 'r').read()\n",
    "lh_pos = lh_pos.split('\\n')\n",
    "users = json.load(open(\"cleaned_large_user_dictionary.json\"))\n",
    "word_list = list(set(lh_pos + lh_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "large_user_number = 76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "#####Pull restaurant data for a given user\n",
    "ip = '54.175.170.119'\n",
    "conn = MongoClient(ip, 27017)\n",
    "conn.database_names()\n",
    "db = conn.get_database('cleaned_data')\n",
    "reviews = db.get_collection('restaurant_reviews')\n",
    "\n",
    "for j in tqdm.tqdm(range(70, 100)):\n",
    "    user_df = yml.make_user_df(users[users.keys()[j]])\n",
    "    business_ids = list(set(user_df['biz_id']))\n",
    "    restreview = {}\n",
    "\n",
    "    for i in range(0, len(business_ids)):\n",
    "        rlist = []\n",
    "        for obj in reviews.find({'business_id':business_ids[i]}):\n",
    "            rlist.append(obj)\n",
    "        restreview[business_ids[i]] = rlist\n",
    "    restaurant_df = yml.make_biz_df(users.keys()[j], restreview)\n",
    "    \n",
    "    #Create a training and test sample from the user reviewed restaurants\n",
    "    split_samp = .25\n",
    "    len_random = int(len(business_ids) * split_samp)\n",
    "    test_set = random.sample(business_ids, len_random)\n",
    "    training_set = [x for x in business_ids if x not in test_set]\n",
    "    sub_train_reviews, train_labels, train_reviews, train_ratings = [], [], [], []\n",
    "\n",
    "    #Create a list of training reviews and training ratings\n",
    "    for rest_id in training_set:\n",
    "        train_reviews.append((user_df[user_df['biz_id'] == rest_id]['review_text'].iloc[0],\n",
    "                                 user_df[user_df['biz_id'] == rest_id]['rating'].iloc[0]))\n",
    "\n",
    "    #Create an even sample s.t. len(positive_reviews) = len(negative_reviews)\n",
    "    sample_size = min(len([x[1] for x in train_reviews if x[1] < 4]),\n",
    "                          len([x[1] for x in train_reviews if x[1] >= 4]))\n",
    "    \n",
    "    bad_reviews = [x for x in train_reviews if x[1] < 4]\n",
    "    good_reviews = [x for x in train_reviews if x[1] >= 4]\n",
    "\n",
    "    for L in range(0, int(float(sample_size)/float(2))):\n",
    "        sub_train_reviews.append(bad_reviews[L][0])\n",
    "        sub_train_reviews.append(good_reviews[L][0])\n",
    "        train_labels.append(bad_reviews[L][1])\n",
    "        train_labels.append(good_reviews[L][1])\n",
    "        \n",
    "    #Make the train labels binary\n",
    "    train_labels = [1 if x >=4 else 0 for x in train_labels]\n",
    "    \n",
    "    #Fit LSI model and return number of LSI topics\n",
    "    lsi, topics, dictionary = yml.fit_lsi(sub_train_reviews)\n",
    "\n",
    "    #Make a FeatureUnion object with the desired features then fit to train reviews\n",
    "    test_results = {}\n",
    "    feature_selection = {\"sent_tf\":(True, True, False), \n",
    "                         \"sent\": (True,False,False),\n",
    "                         \"tf_lda\": (False,True,True), \n",
    "                         \"all\": (True, True, True)}\n",
    "\n",
    "    for feature in feature_selection.keys():\n",
    "        #Make a FeatureUnion object with the desired features then fit to train reviews\n",
    "        comb_features = yml.make_featureunion(sent_percent=feature_selection[feature][0], \n",
    "                                              tf = feature_selection[feature][1], \n",
    "                                              lda = feature_selection[feature][2])\n",
    "        \n",
    "        delta_vect = None\n",
    "        comb_features.fit(sub_train_reviews)\n",
    "        train_features = comb_features.transform(sub_train_reviews)\n",
    "        train_lsi = yml.get_lsi_features(sub_train_reviews, lsi, topics, dictionary)\n",
    "        train_features = sparse.hstack((train_features, train_lsi))\n",
    "        train_features = train_features.todense()\n",
    "\n",
    "        #Fit LSI model and return number of LSI topics\n",
    "        lsi, topics, dictionary = yml.fit_lsi(sub_train_reviews)\n",
    "        \n",
    "        #fit each model in turn \n",
    "        model_runs = {\"svm\": (True, False, False),\n",
    "                      \"rf\": (False, True, False), \n",
    "                      \"naive_bayes\": (False, False, True)}\n",
    "\n",
    "        for model_run in model_runs.keys():\n",
    "            clf = yml.fit_model(train_features, train_labels, svm_clf = model_runs[model_run][0], \n",
    "                            RandomForest = model_runs[model_run][1], \n",
    "                                nb = model_runs[model_run][2])\n",
    "            threshold = 0.7\n",
    "            error = yml.test_user_set(test_set, clf, restaurant_df, user_df, comb_features, \n",
    "                                      threshold, lsi, topics, dictionary, delta_vect)\n",
    "            test_results[(feature, model_run)] = (yml.get_log_loss(error), \n",
    "                                            yml.get_accuracy_score(error), \n",
    "                                            yml.get_precision_score(error))\n",
    "    \n",
    "    string_keys_dict = {}\n",
    "    for key in test_results.keys():\n",
    "        string_keys_dict[str(key)] = test_results[key]\n",
    "            \n",
    "with open('test_results.json', 'wb') as fp:\n",
    "    json.dump(string_keys_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_results = string_keys_dict.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"('all', 'naive_bayes')\": (-0.35531558821035314, 0.49295774647887325, 0.5),\n",
       " \"('all', 'rf')\": (-0.8133847697787171, 0.49295774647887325, 0.5),\n",
       " \"('all', 'svm')\": (-0.8399640423809434,\n",
       "  0.36619718309859156,\n",
       "  0.6046511627906976),\n",
       " \"('sent', 'naive_bayes')\": (-0.9427207768388881,\n",
       "  0.5492957746478874,\n",
       "  0.46296296296296297),\n",
       " \"('sent', 'rf')\": (-0.03605482107092158, 0.49295774647887325, 0.0),\n",
       " \"('sent', 'svm')\": (-0.27756518605734753, 0.49295774647887325, 0.5),\n",
       " \"('sent_tf', 'naive_bayes')\": (-0.448129757136043, 0.49295774647887325, 0.5),\n",
       " \"('sent_tf', 'rf')\": (-0.16551179418463383, 0.49295774647887325, 0.0),\n",
       " \"('sent_tf', 'svm')\": (-0.44496246323770344, 0.49295774647887325, 0.5),\n",
       " \"('tf_lda', 'naive_bayes')\": (-0.44581605225654675, 0.49295774647887325, 0.5),\n",
       " \"('tf_lda', 'rf')\": (-0.4093586504561011, 0.49295774647887325, 0.5),\n",
       " \"('tf_lda', 'svm')\": (-0.6585684158330528,\n",
       "  0.5492957746478874,\n",
       "  0.4166666666666667)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/sklearn/feature_extraction/text.py:764: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  feature_idx = vocabulary[feature]\n",
      "100%|██████████| 1/1 [00:39<00:00, 39.66s/it]\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "#Make a Recommendation\n",
    "#########################\n",
    "top_results = []\n",
    "#Get feature and model combination that yields the highest precision\n",
    "for key in test_results.keys():\n",
    "    feat_model = make_tuple(key)\n",
    "    if not top_results:\n",
    "        top_results = [(feat_model,test_results[key][2])]\n",
    "    else:\n",
    "        if test_results[key][2] > top_results[0][1]:\n",
    "            top_results.pop()\n",
    "            top_results = [(feat_model, test_results[key][2])]\n",
    "feat_result = top_results[0][0][0]\n",
    "model_result = top_results[0][0][1]\n",
    "\n",
    "for j in tqdm.tqdm(range(large_user_number, large_user_number+1)):\n",
    "    user_df = yml.make_user_df(users[users.keys()[j]])\n",
    "    business_ids = list(set(user_df['biz_id']))\n",
    "\n",
    "    #Create a list of training reviews and training ratings\n",
    "    for rest_id in business_ids:\n",
    "        train_reviews.append((user_df[user_df['biz_id'] == rest_id]['review_text'].iloc[0],\n",
    "                                 user_df[user_df['biz_id'] == rest_id]['rating'].iloc[0]))\n",
    "\n",
    "    #Create an even sample s.t. len(positive_reviews) = len(negative_reviews)\n",
    "    sample_size = min(len([x[1] for x in train_reviews if x[1] < 4]),\n",
    "                          len([x[1] for x in train_reviews if x[1] >= 4]))\n",
    "    \n",
    "    bad_reviews = [x for x in train_reviews if x[1] < 4]\n",
    "    good_reviews = [x for x in train_reviews if x[1] >= 4]\n",
    "    \n",
    "    train_labels = []\n",
    "    sub_train_reviews = []\n",
    "    for L in range(0, int(float(sample_size)/float(2))):\n",
    "        sub_train_reviews.append(bad_reviews[L][0])\n",
    "        sub_train_reviews.append(good_reviews[L][0])\n",
    "        train_labels.append(bad_reviews[L][1])\n",
    "        train_labels.append(good_reviews[L][1])\n",
    "        \n",
    "    #Make the train labels binary\n",
    "    train_labels = [1 if x >=4 else 0 for x in train_labels]\n",
    "    \n",
    "    #Fit LSI model and return number of LSI topics\n",
    "    lsi, topics, dictionary = yml.fit_lsi(sub_train_reviews)\n",
    "\n",
    "    #Make a FeatureUnion object with the desired features then fit to train reviews\n",
    "    feature_selection = {\"sent_tf\":(True, True, False), \n",
    "                         \"sent\": (True,False,False),\n",
    "                         \"tf_lda\": (False,True,True), \n",
    "                         \"all\": (True, True, True)}\n",
    "    top_feature = feature_selection['all']\n",
    "    \n",
    "    comb_features = yml.make_featureunion(sent_percent=top_feature[0], \n",
    "                                          tf = top_feature[1], \n",
    "                                          lda = top_feature[2])\n",
    "        \n",
    "    comb_features.fit(sub_train_reviews)\n",
    "    train_features = comb_features.transform(sub_train_reviews)\n",
    "    train_lsi = yml.get_lsi_features(sub_train_reviews, lsi, topics, dictionary)\n",
    "    train_features = sparse.hstack((train_features, train_lsi))\n",
    "    train_features = train_features.todense()\n",
    "\n",
    "    #Fit LSI model and return number of LSI topics\n",
    "    lsi, topics, dictionary = yml.fit_lsi(sub_train_reviews)\n",
    "        \n",
    "    #Get the top performing model and fit using that model\n",
    "    model_runs = {\"svm\": (True, False, False),\n",
    "                  \"rf\": (False, True, False), \n",
    "                  \"naive_bayes\": (False, False, True)}\n",
    "    top_model = model_runs['svm']\n",
    "    clf = yml.fit_model(train_features, train_labels, svm_clf = top_model[0], \n",
    "                RandomForest = top_model[1], \n",
    "                    nb = top_model[2])\n",
    "\n",
    "    threshold = 0.7\n",
    "    user_results = yml.make_rec(dc_reviews, clf, threshold, comb_features, \n",
    "                                lsi, topics, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################################################################\n",
    "#Collect the results into a list of tuples, then select the top\n",
    "#5 most confident good recs and top 5 most confident bad recs\n",
    "################################################################\n",
    "\n",
    "tuple_results = []\n",
    "for result in user_results:\n",
    "    tuple_results.append((result[1], result[2], result[3]))\n",
    "    \n",
    "#Sort the list of tuples by predicition confidence\n",
    "tuple_results = sorted(tuple_results, key=lambda tup: tup[1])\n",
    "top_5 = tuple_results[-5:]\n",
    "bottom_5 = tuple_results[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'/biz/potters-house-washington', 0.90000000000000002, 1),\n",
       " (u'/biz/rice-bar-washington-4', 0.90000000000000002, 1),\n",
       " (u'/biz/that-cheesecake-truck-washington-2', 0.90000000000000002, 1),\n",
       " (u'/biz/little-sesame-washington', 0.90000000000000002, 1),\n",
       " (u'/biz/ching-ching-cha-washington', 0.94999999999999996, 1)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the top 5 restaurants\n",
    "top_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'/biz/lukes-lobster-georgetown-washington', 0.050000000000000003, 0),\n",
       " (u'/biz/good-stuff-eatery-washington-2', 0.050000000000000003, 0),\n",
       " (u'/biz/bold-bite-washington', 0.050000000000000003, 0),\n",
       " (u'/biz/macintyres-washington', 0.14999999999999999, 0),\n",
       " (u'/biz/takoda-restaurant-and-beer-garden-washington-2',\n",
       "  0.14999999999999999,\n",
       "  0)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the bottom 5 restaurants\n",
    "bottom_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>biz_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24f5ie972m_bYpirVW-dZA</td>\n",
       "      <td>4</td>\n",
       "      <td>As far as international pizza chains goes Roun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1lRytuj8IdLMHDFl2LetxA</td>\n",
       "      <td>1</td>\n",
       "      <td>DO THIS FIRSTSign up and get the Club Palms ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G-O_a7168Id7E0wIgHKtVw</td>\n",
       "      <td>3</td>\n",
       "      <td>I had my doubts about this new Thai restaurant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FVospBWddyS7IpbEuFSqgQ</td>\n",
       "      <td>2</td>\n",
       "      <td>Maybe my expectations were higher than normal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4I4OoW0tbaoG4I4D2spF3w</td>\n",
       "      <td>4</td>\n",
       "      <td>Del Taco insert greater than sign Taco Bell   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   biz_id  rating  \\\n",
       "0  24f5ie972m_bYpirVW-dZA       4   \n",
       "1  1lRytuj8IdLMHDFl2LetxA       1   \n",
       "2  G-O_a7168Id7E0wIgHKtVw       3   \n",
       "3  FVospBWddyS7IpbEuFSqgQ       2   \n",
       "4  4I4OoW0tbaoG4I4D2spF3w       4   \n",
       "\n",
       "                                         review_text  \n",
       "0  As far as international pizza chains goes Roun...  \n",
       "1  DO THIS FIRSTSign up and get the Club Palms ca...  \n",
       "2  I had my doubts about this new Thai restaurant...  \n",
       "3  Maybe my expectations were higher than normal ...  \n",
       "4  Del Taco insert greater than sign Taco Bell   ...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#user_df contains all of the user's reviews, with one column of restaurants,\n",
    "#one column of the user's ratings, and one column with the user's reviews\n",
    "user_df.head()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
