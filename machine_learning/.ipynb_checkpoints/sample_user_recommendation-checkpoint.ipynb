{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "from ast import literal_eval as make_tuple\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "from pymongo import MongoClient\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import sys\n",
    "sys.path.append('../machine_learning')\n",
    "import yelp_ml as yml\n",
    "reload(yml)\n",
    "from gensim import corpora, models, similarities, matutils\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Scrapped Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dc_reviews = json.load(open(\"../Yelp_web_scrapper/dc_reviews.json\"))\n",
    "newyork_reviews = json.load(open(\"../Yelp_web_scrapper/newyork_reviews.json\"))\n",
    "austin_reviews = json.load(open(\"../Yelp_web_scrapper/austin_reviews.json\"))\n",
    "chicago_reviews = json.load(open(\"../Yelp_web_scrapper/chicago_reviews.json\"))\n",
    "la_reviews = json.load(open(\"../Yelp_web_scrapper/la_reviews.json\"))\n",
    "\n",
    "scrapped_reviews = {'dc': dc_reviews, 'ny': newyork_reviews, \n",
    "                    'austin': austin_reviews, 'chicago': chicago_reviews, \n",
    "                    'la': la_reviews}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Hu & Liu (2004) Word Dictionary and Wrangled Large Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lh_neg = open('../input/negative-words.txt', 'r').read()\n",
    "lh_neg = lh_neg.split('\\n')\n",
    "lh_pos = open('../input/positive-words.txt', 'r').read()\n",
    "lh_pos = lh_pos.split('\\n')\n",
    "users = json.load(open(\"cleaned_large_user_dictionary.json\"))\n",
    "word_list = list(set(lh_pos + lh_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the AWS Instance and get the restaurant reviews from the cleaned data database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ip = '54.175.170.119'\n",
    "conn = MongoClient(ip, 27017)\n",
    "conn.database_names()\n",
    "db = conn.get_database('cleaned_data')\n",
    "reviews = db.get_collection('restaurant_reviews')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the following features we combine them with one of the three models. We perform the testing procedure and collect the results in a dictionary object.\n",
    "\n",
    "#### Features:\n",
    "                                 \n",
    "1. (Sentiment %, TF-IDF w/ (2,2) N-Gram, LSA)\n",
    "2. (Sentiment %, LSA)\n",
    "3. (TF-IDF w/ (2,2) N-Gram, LDA, LSA)\n",
    "4. (Sentiment %, TF-IDF w/ (2,2) N-Gram, LDA, LSA)\n",
    "                  \n",
    "#### Models:\n",
    "1. Linear Support Vector Machine\n",
    "2. Random Forest\n",
    "3. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "100%|██████████| 1/1 [13:22<00:00, 802.10s/it]\n"
     ]
    }
   ],
   "source": [
    "string_keys_dict = {}\n",
    "for j in tqdm.tqdm(range(146, 147)):\n",
    "    \n",
    "    #Generate a dataframe that has the user's review text, review rating, and restaurant ID\n",
    "    test_results = {}\n",
    "    user_df = yml.make_user_df(users[users.keys()[j]])\n",
    "    \n",
    "    #Only predict for the user if they have at least 20 bad ratings\n",
    "    if len([x for x in user_df['rating'] if x < 4]) < 20:\n",
    "        string_keys_dict[str(users.keys()[j])] = test_results\n",
    "        continue\n",
    "    else:\n",
    "        business_ids = list(set(user_df['biz_id']))\n",
    "        restreview = {}\n",
    "        \n",
    "        #Create a training and test sample from the user reviewed restaurants\n",
    "        #using a random 25% subset of all the restaurants the user has reviewed\n",
    "        split_samp = .25\n",
    "        len_random = int(len(business_ids) * split_samp)\n",
    "        test_set = random.sample(business_ids, len_random)\n",
    "        training_set = [x for x in business_ids if x not in test_set]\n",
    "        sub_train_reviews, train_labels, train_reviews, train_ratings = [], [], [], []\n",
    "\n",
    "        #Create a list with the tuple (training review, training rating) \n",
    "        for rest_id in training_set:\n",
    "            train_reviews.append((user_df[user_df['biz_id'] == rest_id]['review_text'].iloc[0],\n",
    "                                     user_df[user_df['biz_id'] == rest_id]['rating'].iloc[0]))\n",
    "\n",
    "        #Note that the distribution is heavily skewed towards good reviews. \n",
    "        #Therefore, we create a training sample with the same amount of\n",
    "        #positive and negative reviews\n",
    "        sample_size = min(len([x[1] for x in train_reviews if x[1] < 4]),\n",
    "                              len([x[1] for x in train_reviews if x[1] >= 4]))\n",
    "\n",
    "        bad_reviews = [x for x in train_reviews if x[1] < 4]\n",
    "        good_reviews = [x for x in train_reviews if x[1] >= 4]\n",
    "\n",
    "        for L in range(0, int(float(sample_size)/float(2))):\n",
    "            sub_train_reviews.append(bad_reviews[L][0])\n",
    "            sub_train_reviews.append(good_reviews[L][0])\n",
    "            train_labels.append(bad_reviews[L][1])\n",
    "            train_labels.append(good_reviews[L][1])\n",
    "\n",
    "        #Make the train labels binary\n",
    "        train_labels = [1 if x >=4 else 0 for x in train_labels]\n",
    "        \n",
    "        #Sanity check for non-empty training reviews\n",
    "        if not sub_train_reviews:\n",
    "            string_keys_dict[str(users.keys()[j])] = test_results\n",
    "            continue\n",
    "        else:\n",
    "            for i in range(0, len(business_ids)):\n",
    "                rlist = []\n",
    "                for obj in reviews.find({'business_id':business_ids[i]}):\n",
    "                    rlist.append(obj)\n",
    "                restreview[business_ids[i]] = rlist\n",
    "\n",
    "            restaurant_df = yml.make_biz_df(users.keys()[j], restreview)\n",
    "\n",
    "            #Make a FeatureUnion object with the desired features then fit to train reviews\n",
    "            feature_selection = {\"sent_tf\":(True, True, False), \n",
    "                                 \"sent\": (True,False,False),\n",
    "                                 \"tf_lda\": (False,True,True), \n",
    "                                 \"all\": (True, True, True)}\n",
    "\n",
    "            for feature in feature_selection.keys():\n",
    "                #Make a FeatureUnion object with the desired features then fit to train reviews\n",
    "                comb_features = yml.make_featureunion(sent_percent=feature_selection[feature][0], \n",
    "                                                      tf = feature_selection[feature][1], \n",
    "                                                      lda = feature_selection[feature][2])\n",
    "\n",
    "                delta_vect = None\n",
    "                comb_features.fit(sub_train_reviews)\n",
    "                train_features = comb_features.transform(sub_train_reviews)\n",
    "\n",
    "                #Fit LSI model and return number of LSI topics\n",
    "                lsi, topics, dictionary = yml.fit_lsi(sub_train_reviews)\n",
    "                train_lsi = yml.get_lsi_features(sub_train_reviews, lsi, topics, dictionary)\n",
    "\n",
    "                #Stack the LSI and combined features together\n",
    "                train_features = sparse.hstack((train_features, train_lsi))\n",
    "                train_features = train_features.todense()\n",
    "\n",
    "                #fit each model in turn \n",
    "                model_runs = {\"svm\": (True, False, False),\n",
    "                              \"rf\": (False, True, False), \n",
    "                              \"naive_bayes\": (False, False, True)}\n",
    "\n",
    "                for model_run in model_runs.keys():\n",
    "                    clf = yml.fit_model(train_features, train_labels, svm_clf = model_runs[model_run][0], \n",
    "                                    RandomForest = model_runs[model_run][1], \n",
    "                                        nb = model_runs[model_run][2])\n",
    "                    threshold = 0.7\n",
    "                    error = yml.test_user_set(test_set, clf, restaurant_df, user_df, comb_features, \n",
    "                                              threshold, lsi, topics, dictionary, delta_vect)\n",
    "                    test_results[str((feature, model_run))] = (yml.get_log_loss(error), \n",
    "                                                    yml.get_accuracy_score(error), \n",
    "                                                    yml.get_precision_score(error))\n",
    "                \n",
    "    string_keys_dict[str(users.keys()[j])] = test_results\n",
    "            \n",
    "with open('test_results.json', 'wb') as fp:\n",
    "    json.dump(string_keys_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/sklearn/feature_extraction/text.py:764: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  feature_idx = vocabulary[feature]\n",
      "100%|██████████| 1/1 [04:05<00:00, 245.56s/it]\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "#Make a Recommendation\n",
    "#########################\n",
    "top_results = []\n",
    "#Get feature and model combination that yields the highest precision\n",
    "for key in test_results.keys():\n",
    "    feat_model = make_tuple(key)\n",
    "    if not top_results:\n",
    "        top_results = [(feat_model,test_results[key][2])]\n",
    "    else:\n",
    "        if test_results[key][2] > top_results[0][1]:\n",
    "            top_results.pop()\n",
    "            top_results = [(feat_model, test_results[key][2])]\n",
    "feat_result = top_results[0][0][0]\n",
    "model_result = top_results[0][0][1]\n",
    "\n",
    "for j in tqdm.tqdm(range(156, 157)):\n",
    "    user_df = yml.make_user_df(users[users.keys()[j]])\n",
    "    business_ids = list(set(user_df['biz_id']))\n",
    "\n",
    "    #Create a list of training reviews and training ratings\n",
    "    for rest_id in business_ids:\n",
    "        train_reviews.append((user_df[user_df['biz_id'] == rest_id]['review_text'].iloc[0],\n",
    "                                 user_df[user_df['biz_id'] == rest_id]['rating'].iloc[0]))\n",
    "\n",
    "    #Create an even sample s.t. len(positive_reviews) = len(negative_reviews)\n",
    "    sample_size = min(len([x[1] for x in train_reviews if x[1] < 4]),\n",
    "                          len([x[1] for x in train_reviews if x[1] >= 4]))\n",
    "    \n",
    "    bad_reviews = [x for x in train_reviews if x[1] < 4]\n",
    "    good_reviews = [x for x in train_reviews if x[1] >= 4]\n",
    "    \n",
    "    train_labels = []\n",
    "    sub_train_reviews = []\n",
    "    for L in range(0, int(float(sample_size)/float(2))):\n",
    "        sub_train_reviews.append(bad_reviews[L][0])\n",
    "        sub_train_reviews.append(good_reviews[L][0])\n",
    "        train_labels.append(bad_reviews[L][1])\n",
    "        train_labels.append(good_reviews[L][1])\n",
    "        \n",
    "    #Make the train labels binary\n",
    "    train_labels = [1 if x >=4 else 0 for x in train_labels]\n",
    "    \n",
    "    #Fit LSI model and return number of LSI topics\n",
    "    lsi, topics, dictionary = yml.fit_lsi(sub_train_reviews)\n",
    "\n",
    "    #Make a FeatureUnion object with the desired features then fit to train reviews\n",
    "    feature_selection = {\"sent_tf\":(True, True, False), \n",
    "                         \"sent\": (True,False,False),\n",
    "                         \"tf_lda\": (False,True,True), \n",
    "                         \"all\": (True, True, True)}\n",
    "    top_feature = feature_selection['all']\n",
    "    \n",
    "    comb_features = yml.make_featureunion(sent_percent=top_feature[0], \n",
    "                                          tf = top_feature[1], \n",
    "                                          lda = top_feature[2])\n",
    "        \n",
    "    comb_features.fit(sub_train_reviews)\n",
    "    train_features = comb_features.transform(sub_train_reviews)\n",
    "    train_lsi = yml.get_lsi_features(sub_train_reviews, lsi, topics, dictionary)\n",
    "    train_features = sparse.hstack((train_features, train_lsi))\n",
    "    train_features = train_features.todense()\n",
    "\n",
    "    #Fit LSI model and return number of LSI topics\n",
    "    lsi, topics, dictionary = yml.fit_lsi(sub_train_reviews)\n",
    "        \n",
    "    #Get the top performing model and fit using that model\n",
    "    model_runs = {\"svm\": (True, False, False),\n",
    "                  \"rf\": (False, True, False), \n",
    "                  \"naive_bayes\": (False, False, True)}\n",
    "    \n",
    "    top_model = model_runs['svm']\n",
    "    clf = yml.fit_model(train_features, train_labels, svm_clf = top_model[0], \n",
    "                RandomForest = top_model[1], \n",
    "                    nb = top_model[2])\n",
    "\n",
    "    threshold = 0.7\n",
    "    user_results = {}\n",
    "    for key in scrapped_reviews.keys():\n",
    "        user_results[key] = yml.make_rec(scrapped_reviews[key], clf, threshold, comb_features, \n",
    "                                lsi, topics, dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the results for each of the (feature, model) combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"('all', 'naive_bayes')\": (-0.1511189162804151, 0.5789473684210527, 0.0),\n",
       " \"('all', 'rf')\": (-0.4116323809946996, 0.6052631578947368, 0.0),\n",
       " \"('all', 'svm')\": (-0.20842705948248794, 0.5526315789473685, 1.0),\n",
       " \"('sent', 'naive_bayes')\": (-0.08991266041456705, 0.5789473684210527, 0.0),\n",
       " \"('sent', 'rf')\": (-0.42634916761967867, 0.5789473684210527, 0.0),\n",
       " \"('sent', 'svm')\": (-0.16702688776629532, 0.5789473684210527, 0.0),\n",
       " \"('sent_tf', 'naive_bayes')\": (-0.6600113932517605,\n",
       "  0.39473684210526316,\n",
       "  0.6521739130434783),\n",
       " \"('sent_tf', 'rf')\": (-0.23303580283456787, 0.5789473684210527, 0.0),\n",
       " \"('sent_tf', 'svm')\": (-0.17512097968036375, 0.5789473684210527, 0.0),\n",
       " \"('tf_lda', 'naive_bayes')\": (-0.3788904009513677, 0.5263157894736842, 0.75),\n",
       " \"('tf_lda', 'rf')\": (-0.8065270274851862,\n",
       "  0.47368421052631576,\n",
       "  0.5666666666666667),\n",
       " \"('tf_lda', 'svm')\": (-0.14335362203303773, 0.5526315789473685, 1.0)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################################################################\n",
    "#Collect the results into a list of tuples, then select the top\n",
    "#5 most confident good recs and top 5 most confident bad recs \n",
    "#for each location\n",
    "################################################################\n",
    "tuple_results = {}\n",
    "for key in user_results.keys():\n",
    "    tuple_results[key] = []\n",
    "    for result in user_results[key]:\n",
    "        tuple_results[key].append((result[1], result[2], result[3]))\n",
    "    tuple_results[key] = sorted(tuple_results[key], key=lambda tup: tup[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 recommendations for ny are: \n",
      "[(u'/biz/oceanic-boil-jackson-heights', 1.0, 1), (u'/biz/mozzarella-and-vino-new-york', 1.0, 1), (u'/biz/little-egypt-ridgewood', 1.0, 1), (u'/biz/badshah-modern-indian-new-york', 1.0, 1), (u'/biz/jongro-bbq-new-york-3', 1.0, 1)]\n",
      "The top 5 recommendations for la are: \n",
      "[(u'/biz/cava-santa-monica-2', 1.0, 1), (u'/biz/asuka-los-angeles-2', 1.0, 1), (u'/biz/casa-fina-restaurant-and-cantina-los-angeles', 1.0, 1), (u'/biz/sugarfish-by-sushi-nozawa-los-angeles-10', 1.0, 1), (u'/biz/fathers-office-los-angeles', 1.0, 1)]\n",
      "The top 5 recommendations for austin are: \n",
      "[(u'/biz/mosaic-market-austin-2', 1.0, 1), (u'/biz/il-forte-austin', 1.0, 1), (u'/biz/supper-friends-austin', 1.0, 1), (u'/biz/kerbey-lane-cafe-westlake-austin-4', 1.0, 1), (u'/biz/la-fruta-feliz-austin', 1.0, 1)]\n",
      "The top 5 recommendations for dc are: \n",
      "[(u'/biz/crisp-kitchen-bar-washington', 1.0, 1), (u'/biz/kyirisan-washington', 1.0, 1), (u'/biz/marcels-by-robert-wiedmaier-washington', 1.0, 1), (u'/biz/brick-lane-washington', 1.0, 1), (u'/biz/kotobuki-washington', 1.0, 1)]\n",
      "The top 5 recommendations for chicago are: \n",
      "[(u'/biz/ricobenes-chicago-4', 1.0, 1), (u'/biz/the-windsor-chicago', 1.0, 1), (u'/biz/cairo-kebab-chicago-3', 1.0, 1), (u'/biz/marios-table-chicago', 1.0, 1), (u'/biz/ugos-kitchen-and-bar-chicago', 1.0, 1)]\n"
     ]
    }
   ],
   "source": [
    "#Show the top 5 restaurants for each location\n",
    "for key in tuple_results.keys():\n",
    "    print \"The top 5 recommendations for \" + key + \" are: \"\n",
    "    print tuple_results[key][-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bottom 5 recommendations for ny are: \n",
      "[(u'/biz/black-thai-jackson-heights-4', 0.69999999999999996, 1), (u'/biz/saigon-shack-new-york', 0.75, 1), (u'/biz/dannee-brooklyn', 0.75, 1), (u'/biz/up-thai-new-york', 0.80000000000000004, 1), (u'/biz/pho-vietnam-brooklyn', 0.80000000000000004, 1)]\n",
      "The bottom 5 recommendations for la are: \n",
      "[(u'/biz/dinos-burgers-los-angeles', 0.75, 1), (u'/biz/flavors-of-thai-los-angeles-2', 0.75, 1), (u'/biz/gushi-los-angeles', 0.75, 1), (u'/biz/c-and-m-cafe-los-angeles-6', 0.80000000000000004, 1), (u'/biz/cilantro-lime-los-angeles', 0.80000000000000004, 1)]\n",
      "The bottom 5 recommendations for austin are: \n",
      "[(u'/biz/kesos-taco-house-austin-2', 0.69999999999999996, 1), (u'/biz/thai-kruefha-austin-6', 0.75, 1), (u'/biz/my-thai-mom-austin', 0.75, 1), (u'/biz/javis-best-of-tex-mex-austin-3', 0.80000000000000004, 1), (u'/biz/el-taquito-austin', 0.80000000000000004, 1)]\n",
      "The bottom 5 recommendations for dc are: \n",
      "[(u'/biz/grand-trunk-washington', 0.80000000000000004, 1), (u'/biz/hitching-post-washington', 0.80000000000000004, 1), (u'/biz/lets-mix-bibija-washington', 0.80000000000000004, 1), (u'/biz/soi-38-washington-2', 0.84999999999999998, 1), (u'/biz/simit-smith-washington', 0.84999999999999998, 1)]\n",
      "The bottom 5 recommendations for chicago are: \n",
      "[(u'/biz/golden-thai-chicago', 0.75, 1), (u'/biz/thai-spoon-chicago-4', 0.75, 1), (u'/biz/star-kitchen-chicago', 0.75, 1), (u'/biz/chavas-tacos-chicago', 0.80000000000000004, 1), (u'/biz/frontera-fresco-chicago', 0.80000000000000004, 1)]\n"
     ]
    }
   ],
   "source": [
    "#Show the top 5 restaurants for each location\n",
    "for key in tuple_results.keys():\n",
    "    print \"The bottom 5 recommendations for \" + key + \" are: \"\n",
    "    print tuple_results[key][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>biz_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM4ivx69oX71Dsveu26Tmw</td>\n",
       "      <td>4</td>\n",
       "      <td>So Wednesday evening I needed milk and cat foo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2BbFeotL85cIaBjSq1SWiA</td>\n",
       "      <td>4</td>\n",
       "      <td>I am getting to this a bit late as I was there...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KRsANC7TzP97KMFRA1JqiQ</td>\n",
       "      <td>4</td>\n",
       "      <td>So I wasnt sure where I wanted to eat lunch to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3TnNC-AMuQ4upCtcgtU49w</td>\n",
       "      <td>3</td>\n",
       "      <td>I had a Groupon for this place how many review...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5Je2-6KDxPQJZdItfo1ngg</td>\n",
       "      <td>4</td>\n",
       "      <td>For my money the best of the 3 or 4 Asian buff...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   biz_id  rating  \\\n",
       "0  BM4ivx69oX71Dsveu26Tmw       4   \n",
       "1  2BbFeotL85cIaBjSq1SWiA       4   \n",
       "2  KRsANC7TzP97KMFRA1JqiQ       4   \n",
       "3  3TnNC-AMuQ4upCtcgtU49w       3   \n",
       "4  5Je2-6KDxPQJZdItfo1ngg       4   \n",
       "\n",
       "                                         review_text  \n",
       "0  So Wednesday evening I needed milk and cat foo...  \n",
       "1  I am getting to this a bit late as I was there...  \n",
       "2  So I wasnt sure where I wanted to eat lunch to...  \n",
       "3  I had a Groupon for this place how many review...  \n",
       "4  For my money the best of the 3 or 4 Asian buff...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#user_df contains all of the user's reviews, ratings, and restaurants reviewed\n",
    "user_df = yml.make_user_df(users[users.keys()[j]])\n",
    "user_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Graph most common word usages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Graph types of restaurants the user likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "toms haps boba tepanyaki arbys\n",
      "Topic 1:\n",
      "delux almond milk problem path\n",
      "Topic 2:\n",
      "santisima shark dogfish la smooth\n",
      "Topic 3:\n",
      "loved rounds overly differences cashier\n",
      "Topic 4:\n",
      "parts vegetarian yolks separation teeth\n",
      "Topic 5:\n",
      "clean dog suggested 13 melt\n",
      "Topic 6:\n",
      "boxing especially nick everyday faster\n",
      "Topic 7:\n",
      "wings pizza fan trips bread\n",
      "Topic 8:\n",
      "container reiteration delivers developed postino\n",
      "Topic 9:\n",
      "pie caramel carrot burritos seven\n",
      "Topic 10:\n",
      "burrito happier wallflower swapping infinite\n",
      "Topic 11:\n",
      "jerk close limited approaching eventually\n",
      "Topic 12:\n",
      "snoh pets mousse froyo ramen\n",
      "Topic 13:\n",
      "grits omelet seek blah visitor\n",
      "Topic 14:\n",
      "norm located smunch crabby problems\n",
      "Topic 15:\n",
      "matthew clumsy dolsot jade bobby\n",
      "Topic 16:\n",
      "coffee songbird yes enchiladas dol\n",
      "Topic 17:\n",
      "keeping good place buffet dog\n",
      "Topic 18:\n",
      "tagliani sampled daring deserts consistent\n",
      "Topic 19:\n",
      "passion truffles thrive fruit aphrodisiac\n",
      "Topic 20:\n",
      "doughnut doughnuts sunny johnnycakes poached\n",
      "Topic 21:\n",
      "reasonably dutch uye hugely benedict\n",
      "Topic 22:\n",
      "lightings welldone brûlée cluster delicate\n",
      "Topic 23:\n",
      "lennys lobster packed clear quiet\n",
      "Topic 24:\n",
      "pizza visits pizzas italy reviewing\n",
      "Topic 25:\n",
      "cream factory waffle refinery diarrhea\n",
      "Topic 26:\n",
      "pizza truck desperate jamburritos josh\n",
      "Topic 27:\n",
      "sambos stew driven row injera\n",
      "Topic 28:\n",
      "noisy burger amber stellar ended\n",
      "Topic 29:\n",
      "zoes pizza outta grandiose fckin\n",
      "Topic 30:\n",
      "favorite finding pig necessarily cramped\n",
      "Topic 31:\n",
      "pizza lived moves stand ricotta\n",
      "Topic 32:\n",
      "food good place lunch time\n",
      "Topic 33:\n",
      "dog acai styrofoam container dogs\n",
      "Topic 34:\n",
      "bbq pork pulled kind barbecue\n",
      "Topic 35:\n",
      "tuna echo sandwich door swallowed\n",
      "Topic 36:\n",
      "quiche liver teppan 3rd claw\n",
      "Topic 37:\n",
      "pizza sans crouched emerges flying\n",
      "Topic 38:\n",
      "salads order dog wanna difference\n",
      "Topic 39:\n",
      "stark handsdown hospitalesque disappointing awkward1980s\n",
      "Topic 40:\n",
      "bars asiany crazy grabbagreen trust\n",
      "Topic 41:\n",
      "looking paris meeting evening packed\n",
      "Topic 42:\n",
      "floor existent deli chuckbox excited\n",
      "Topic 43:\n",
      "invisibility field chile finish worth\n",
      "Topic 44:\n",
      "fig craftsteak granola kensington ncounter\n",
      "Topic 45:\n",
      "certainly tap angela flight yakking\n",
      "Topic 46:\n",
      "dogs trip torn specific sampled\n",
      "Topic 47:\n",
      "wok chafing cook new newer\n",
      "Topic 48:\n",
      "pomegranate subway basis efficient cannoli\n",
      "Topic 49:\n",
      "time fake granola driven itinerary\n"
     ]
    }
   ],
   "source": [
    "#View the top words in the LDA representation\n",
    "vectorizer = TfidfVectorizer(stop_words='english', ngram_range = (1,1))\n",
    "tf = vectorizer.fit_transform(sub_train_reviews)\n",
    "lda_fit = LatentDirichletAllocation(n_topics=50).fit(tf)\n",
    "\n",
    "#Display top words in each topic                     \n",
    "no_top_words = 5\n",
    "tf_feature_names = vectorizer.get_feature_names()\n",
    "yml.display_topics(lda_fit, tf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PUT IN A LSA representation"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
