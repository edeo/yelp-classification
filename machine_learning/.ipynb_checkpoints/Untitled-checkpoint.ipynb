{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "from pymongo import MongoClient\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import xgboost as xgb\n",
    "import sys\n",
    "sys.path.append('../machine_learning')\n",
    "import yelp_ml as yml\n",
    "reload(yml)\n",
    "from gensim import corpora, models, similarities, matutils\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lh_neg = open('../input/negative-words.txt', 'r').read()\n",
    "lh_neg = lh_neg.split('\\n')\n",
    "lh_pos = open('../input/positive-words.txt', 'r').read()\n",
    "lh_pos = lh_pos.split('\\n')\n",
    "users = json.load(open(\"cleaned_large_user_dictionary.json\"))\n",
    "word_list = list(set(lh_pos + lh_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ip = '184.73.129.244'\n",
    "conn = MongoClient(ip, 27017)\n",
    "db = conn.get_database('cleaned_data')\n",
    "reviews = db.get_collection('restaurant_reviews')\n",
    "users_results = pd.DataFrame()\n",
    "user_id = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, True, False)\n",
      "(True, False, False)\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(False, True, False)\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=100, max_features='auto', max_leaf_nodes=50,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "(False, False, True)\n",
      "GaussianNB(priors=None)\n",
      "(True, False, False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, False, False)\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "(False, True, False)\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=100, max_features='auto', max_leaf_nodes=50,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "(False, False, True)\n",
      "GaussianNB(priors=None)\n",
      "(False, True, True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, False, False)\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "(False, True, False)\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=100, max_features='auto', max_leaf_nodes=50,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "(False, False, True)\n",
      "GaussianNB(priors=None)\n",
      "(True, True, True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, False, False)\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "(False, True, False)\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=100, max_features='auto', max_leaf_nodes=50,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "(False, False, True)\n",
      "GaussianNB(priors=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1/1 [13:13<00:00, 793.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "key ((True, True, False), GaussianNB(priors=None)) is not a string",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-6a463d7a0f39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_result.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/robertsonwang/anaconda2/lib/python2.7/json/__init__.pyc\u001b[0m in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, encoding, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;31m# could accelerate with writelines in some versions of Python, at\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;31m# a debuggability cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/robertsonwang/anaconda2/lib/python2.7/json/encoder.pyc\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_iterencode_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/robertsonwang/anaconda2/lib/python2.7/json/encoder.pyc\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"key \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" is not a string\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                 \u001b[0mfirst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: key ((True, True, False), GaussianNB(priors=None)) is not a string"
     ]
    }
   ],
   "source": [
    "for j in tqdm.tqdm(range(0, len(users.keys()[0:1]))):\n",
    "\t\n",
    "\tuser_id.append(users[users.keys()[i]])\n",
    "\n",
    "\tuser_df = yml.make_user_df(users[users.keys()[i]])\n",
    "\tbusiness_ids = list(set(user_df['biz_id']))\n",
    "\trestreview = {}\n",
    "\n",
    "\tfor i in range(0, len(business_ids)):\n",
    "\t\trlist = []\n",
    "\t\tfor obj in reviews.find({'business_id':business_ids[i]}):\n",
    "\t\t\trlist.append(obj)\n",
    "\t\trestreview[business_ids[i]] = rlist\n",
    "\trestaurant_df = yml.make_biz_df(users.keys()[j], restreview)\n",
    "\t\n",
    "\t#Create a training and test sample from the user reviewed restaurants\n",
    "\tsplit_samp = .20\n",
    "\trandom_int = random.randint(1, len(business_ids)-1)\n",
    "\tlen_random = int(len(business_ids) * split_samp)\n",
    "\ttest_set = business_ids[random_int:random_int+len_random]\n",
    "\ttraining_set = business_ids[0:random_int]+business_ids[random_int+len_random:len(business_ids)]\n",
    "\ttrain_reviews, train_ratings = [], []\n",
    "\t\n",
    "\t#Create a list of training reviews and training ratings\n",
    "\tfor rest_id in training_set:\n",
    "\t\ttrain_reviews.extend(list(user_df[user_df['biz_id'] == rest_id]['review_text']))\n",
    "\t\ttrain_ratings.extend(list(user_df[user_df['biz_id'] == rest_id]['rating']))\n",
    "\t\n",
    "\t#Transform the star labels into a binary class problem, 0 if rating is < 4 else 1\n",
    "\ttrain_labels = [1 if x >=4 else 0 for x in train_ratings]\n",
    "\t\n",
    "\t#Fit LSI model and return number of LSI topics\n",
    "\tlsi, topics, dictionary = yml.fit_lsi(train_reviews)\n",
    "\n",
    "\t#Create a training and test sample from the user reviewed restaurants\n",
    "\tsplit_samp = .30\n",
    "\trandom_int = random.randint(1, len(business_ids)-1)\n",
    "\tlen_random = int(len(business_ids) * split_samp)\n",
    "\ttest_set = business_ids[random_int:random_int+len_random]\n",
    "\ttraining_set = business_ids[0:random_int]+business_ids[random_int+len_random:len(business_ids)]\n",
    "\tsub_train_reviews, train_labels, train_reviews, train_ratings = [], [], [], []\n",
    "\n",
    "\t#Create a list of training reviews and training ratings\n",
    "\tfor rest_id in training_set:\n",
    "\t\ttrain_reviews.append((user_df[user_df['biz_id'] == rest_id]['review_text'].iloc[0],\n",
    "\t\t\t\t\t\t\t\t user_df[user_df['biz_id'] == rest_id]['rating'].iloc[0]))\n",
    "\n",
    "\t#Create an even sample s.t. len(positive_reviews) = len(negative_reviews)\n",
    "\tsample_size = min(len([x[1] for x in train_reviews if x[1] < 4]),\n",
    "\t\t\t\t\t\t  len([x[1] for x in train_reviews if x[1] >= 4]))\n",
    "\t\n",
    "\tbad_reviews = [x for x in train_reviews if x[1] < 4]\n",
    "\tgood_reviews = [x for x in train_reviews if x[1] >= 4]\n",
    "\n",
    "\tfor L in range(0, int(float(sample_size)/float(2))):\n",
    "\t\tsub_train_reviews.append(bad_reviews[L][0])\n",
    "\t\tsub_train_reviews.append(good_reviews[L][0])\n",
    "\t\ttrain_labels.append(bad_reviews[L][1])\n",
    "\t\ttrain_labels.append(good_reviews[L][1])\n",
    "        \n",
    "\t#Make the train labels binary\n",
    "\ttrain_labels = [1 if x >=4 else 0 for x in train_labels]\n",
    "    \n",
    "\t#Make a FeatureUnion object with the desired features then fit to train reviews\n",
    "\ttest_results = {}\n",
    "\tfeature_selection = [(True, True, False), (True,False,False), (False,True,True), (True, True, True)]\n",
    "\n",
    "\tfor feature in feature_selection:\n",
    "\t\t#Make a FeatureUnion object with the desired features then fit to train reviews\n",
    "\t\tcomb_features = yml.make_featureunion(sent_percent=feature[0], tf = feature[1], lda = feature[2])\n",
    "\t\tcomb_features.fit(sub_train_reviews)\n",
    "\t\ttrain_features = comb_features.transform(sub_train_reviews)\n",
    "\t\ttrain_lsi = yml.get_lsi_features(sub_train_reviews, lsi, topics, dictionary)\n",
    "\t\ttrain_features = sparse.hstack((train_features, train_lsi))\n",
    "\t\ttrain_features = train_features.todense()\n",
    "\n",
    "\t\t#Fit LSI model and return number of LSI topics\n",
    "\t\tlsi, topics, dictionary = yml.fit_lsi(sub_train_reviews)\n",
    "\t\t\n",
    "\t\t#fit each model in turn \n",
    "\t\tmodel_runs = [(True, False, False), (False, True, False), \n",
    "\t\t\t\t\t  (False, False, True)]\n",
    "\n",
    "\t\tfor model_run in model_runs:\n",
    "\t\t\tclf = yml.fit_model(train_features, train_labels, svm_clf = model_run[0], \n",
    "\t\t\t\t\t\t\tRandomForest = model_run[1], nb = model_run[2])\n",
    "\t\t\tthreshold = 0.7\n",
    "\t\t\terror = yml.test_user_set(test_set, clf, restaurant_df, user_df, comb_features, threshold, lsi, topics, dictionary)\n",
    "\t\t\ttest_results[(feature, clf)] = (yml.get_log_loss(error), yml.get_accuracy_score(error), yml.get_precision_score(error))\n",
    "\n",
    "string_keys_dict = {}\n",
    "for key in test_results.keys():\n",
    "    string_keys_dict[str(key)] = test_results[key]\n",
    "    \n",
    "with open('test_results.json', 'wb') as fp:\n",
    "\tjson.dump(string_keys_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_dict = {}\n",
    "for key in test_results.keys():\n",
    "    new_dict[str(key)] = test_results[key]\n",
    "    \n",
    "with open('test.json', 'wb') as fp:\n",
    "\tjson.dump(new_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = json.load(open('test.json', 'r'))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
