{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'yelp_ml' from 'yelp_ml.pyc'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "from pymongo import MongoClient\n",
    "from nltk.corpus import stopwords\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import xgboost as xgb\n",
    "from gensim import corpora, models, similarities, matutils\n",
    "import tqdm\n",
    "import sys\n",
    "sys.path.append('/Users/robertsonwang/Desktop/Python/Yelp_class/yelp-classification/machine_learning')\n",
    "import yelp_ml as yml\n",
    "reload(yml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary dictionaries and JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lh_neg = open('../input/negative-words.txt', 'r').read()\n",
    "lh_neg = lh_neg.split('\\n')\n",
    "lh_pos = open('../input/positive-words.txt', 'r').read()\n",
    "lh_pos = lh_pos.split('\\n')\n",
    "users = json.load(open(\"cleaned_large_user_dictionary.json\"))\n",
    "word_list = list(set(lh_pos + lh_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 228/228 [00:00<00:00, 235078.99it/s]\n"
     ]
    }
   ],
   "source": [
    "#Fix users JSON\n",
    "users_dict = {}\n",
    "user_ids = []\n",
    "\n",
    "for list_reviews in users['reviews']:\n",
    "    user_ids.append(list_reviews[0]['user_id'])\n",
    "#We have 228 users, creat a new dictionary where the user_ids are the keys and the entries are a list of reviews\n",
    "for i in tqdm.tqdm(range(0, len(user_ids))):\n",
    "    users_dict[user_ids[i]] = users['reviews'][i]\n",
    "with open('cleaned_large_user_dictionary.json', 'wb') as outfile:\n",
    "    json.dump(users_dict, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try running a few tests on a subset of users, the keys are our unique user IDs. We proceed as follows for each user ID:\n",
    "1. Create a user dataframe with the following columns:\n",
    "    * (review_text, review rating, business_id)\n",
    "2. Create a list of unique business IDs for that user\n",
    "3. Connect to the MongoDB server and pull all of the reviews for the restaurants that the user has reviewed\n",
    "4. Create a restaurant dataframe with the following columns:\n",
    "    * (review_text, biz rating, business_id)\n",
    "5. Do a 80/20 training/test split, randomizing over the set of user' reviewed restaurants\n",
    "6. Train the LSI model on the set of training reviews, get the number of topics used in fitting\n",
    "7. Set up the FeatureUnion with the desired features, then fit according to the train reviews and transform the train reviews\n",
    "8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#####Test Machine Learning Algorithms\n",
    "ip = '52.90.170.176'\n",
    "conn = MongoClient(ip, 27017)\n",
    "conn.database_names()\n",
    "db = conn.get_database('cleaned_data')\n",
    "reviews = db.get_collection('restaurant_reviews')\n",
    "\n",
    "for user in users_dict.keys()[0:10]:\n",
    "    user_df = yml.make_user_df(users_dict[user])\n",
    "    business_ids = list(set(user_df['biz_id']))\n",
    "    restreview = {}\n",
    "    for i in range(0, len(business_ids)):\n",
    "        rlist = []\n",
    "        for obj in reviews.find({'business_id':business_ids[i]}):\n",
    "            rlist.append(obj)\n",
    "        restreview[business_ids[i]] = rlist\n",
    "    restaurant_df = yml.make_biz_df(user, restreview)\n",
    "    \n",
    "    #Create a training and test sample from the user reviewed restaurants\n",
    "    split_samp = .30\n",
    "    random_int = random.randint(1, len(business_ids)-1)\n",
    "    len_random = int(len(business_ids) * split_samp)\n",
    "    test_set = business_ids[random_int:random_int+len_random]\n",
    "    training_set = business_ids[0:random_int]+business_ids[random_int+len_random:len(business_ids)]\n",
    "    train_reviews, train_ratings = [], []\n",
    "\n",
    "    #Create a list of training reviews and training ratings\n",
    "    for rest_id in training_set:\n",
    "        train_reviews.extend(list(user_df[user_df['biz_id'] == rest_id]['review_text']))\n",
    "        train_ratings.extend(list(user_df[user_df['biz_id'] == rest_id]['rating']))\n",
    "\n",
    "    #Transform the star labels into a binary class problem, 0 if rating is < 4 else 1\n",
    "    train_labels = [1 if x >=4 else 0 for x in train_ratings]\n",
    "    \n",
    "    #Fit LSI model and return number of LSI topics\n",
    "    lsi, topics, dictionary = yml.fit_lsi(train_reviews)\n",
    "    \n",
    "    #Make a FeatureUnion object with the desired features then fit to train reviews\n",
    "    comb_features = yml.make_featureunion()\n",
    "    comb_features.fit(train_reviews)\n",
    "    \n",
    "    train_features = comb_features.transform(train_reviews)\n",
    "    train_lsi = yml.get_lsi_features(train_reviews, lsi, topics, dictionary)\n",
    "    train_features = sparse.hstack((train_features, train_lsi))\n",
    "    train_features = train_features.todense()\n",
    "    \n",
    "    #fit each model in turn \n",
    "    model_runs = [(True, False, False, False, False), (False, True, False, False, False), \n",
    "                  (False, False, True, False, False), (False, False, False, True, False),\n",
    "                 (False, False, False, False, True)]\n",
    "    test_results = {}\n",
    "    for i in tqdm.tqdm(range(0, len(model_runs))):\n",
    "        clf = yml.fit_model(train_features, train_labels, svm_clf = model_runs[i][0], \n",
    "                        RandomForest = model_runs[i][1], nb = model_runs[i][2])\n",
    "        threshold = 0.7\n",
    "        error = yml.test_user_set(test_set, clf, restaurant_df, user_df, comb_features, threshold, lsi, topics, dictionary)\n",
    "        test_results[clf] = error\n",
    "    break\n",
    "    #Get top predictions\n",
    "    for key in test_results.keys():\n",
    "        results = test_results[test_results.keys()[0]]\n",
    "        log_loss = yml.get_log_loss()\n",
    "        print log_loss\n",
    "        \n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
