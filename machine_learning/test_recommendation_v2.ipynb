{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "from ast import literal_eval as make_tuple\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "from pymongo import MongoClient\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn_deltatfidf import DeltaTfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import xgboost as xgb\n",
    "import sys\n",
    "sys.path.append('../machine_learning')\n",
    "import yelp_ml as yml\n",
    "reload(yml)\n",
    "from gensim import corpora, models, similarities, matutils\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import scrapped reviews\n",
    "dc_reviews = json.load(open(\"../Yelp_web_scrapper/dc_reviews.json\"))\n",
    "newyork_reviews = json.load(open(\"../Yelp_web_scrapper/newyork_reviews.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import word dictionaries\n",
    "lh_neg = open('../input/negative-words.txt', 'r').read()\n",
    "lh_neg = lh_neg.split('\\n')\n",
    "lh_pos = open('../input/positive-words.txt', 'r').read()\n",
    "lh_pos = lh_pos.split('\\n')\n",
    "users = json.load(open(\"cleaned_large_user_dictionary.json\"))\n",
    "word_list = list(set(lh_pos + lh_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      " 50%|█████     | 1/2 [38:14<38:14, 2294.22s/it]/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "100%|██████████| 2/2 [58:57<00:00, 1978.89s/it]\n"
     ]
    }
   ],
   "source": [
    "#####Pull restaurant data for a given user\n",
    "ip = '54.175.170.119'\n",
    "conn = MongoClient(ip, 27017)\n",
    "conn.database_names()\n",
    "db = conn.get_database('cleaned_data')\n",
    "reviews = db.get_collection('restaurant_reviews')\n",
    "string_keys_dict = {}\n",
    "for j in tqdm.tqdm(range(155, 157)):\n",
    "    test_results = {}\n",
    "    user_df = yml.make_user_df(users[users.keys()[j]])\n",
    "    \n",
    "    if len([x for x in user_df['rating'] if x < 4]) < 20:\n",
    "        string_keys_dict[str(users.keys()[j])] = test_results\n",
    "        continue\n",
    "    else:\n",
    "        business_ids = list(set(user_df['biz_id']))\n",
    "        restreview = {}\n",
    "        \n",
    "        #Create a training and test sample from the user reviewed restaurants\n",
    "        split_samp = .25\n",
    "        len_random = int(len(business_ids) * split_samp)\n",
    "        test_set = random.sample(business_ids, len_random)\n",
    "        training_set = [x for x in business_ids if x not in test_set]\n",
    "        sub_train_reviews, train_labels, train_reviews, train_ratings = [], [], [], []\n",
    "\n",
    "        #Create a list of training reviews and training ratings\n",
    "        for rest_id in training_set:\n",
    "            train_reviews.append((user_df[user_df['biz_id'] == rest_id]['review_text'].iloc[0],\n",
    "                                     user_df[user_df['biz_id'] == rest_id]['rating'].iloc[0]))\n",
    "\n",
    "        #Create an even sample s.t. len(positive_reviews) = len(negative_reviews)\n",
    "        sample_size = min(len([x[1] for x in train_reviews if x[1] < 4]),\n",
    "                              len([x[1] for x in train_reviews if x[1] >= 4]))\n",
    "\n",
    "        bad_reviews = [x for x in train_reviews if x[1] < 4]\n",
    "        good_reviews = [x for x in train_reviews if x[1] >= 4]\n",
    "\n",
    "        for L in range(0, int(float(sample_size)/float(2))):\n",
    "            sub_train_reviews.append(bad_reviews[L][0])\n",
    "            sub_train_reviews.append(good_reviews[L][0])\n",
    "            train_labels.append(bad_reviews[L][1])\n",
    "            train_labels.append(good_reviews[L][1])\n",
    "\n",
    "        #Make the train labels binary\n",
    "        train_labels = [1 if x >=4 else 0 for x in train_labels]\n",
    "        \n",
    "        if not sub_train_reviews:\n",
    "            string_keys_dict[str(users.keys()[j])] = test_results\n",
    "            continue\n",
    "        else:\n",
    "            for i in range(0, len(business_ids)):\n",
    "                rlist = []\n",
    "                for obj in reviews.find({'business_id':business_ids[i]}):\n",
    "                    rlist.append(obj)\n",
    "                restreview[business_ids[i]] = rlist\n",
    "\n",
    "            restaurant_df = yml.make_biz_df(users.keys()[j], restreview)\n",
    "\n",
    "            #Make a FeatureUnion object with the desired features then fit to train reviews\n",
    "            feature_selection = {\"sent_tf\":(True, True, False), \n",
    "                                 \"sent\": (True,False,False),\n",
    "                                 \"tf_lda\": (False,True,True), \n",
    "                                 \"all\": (True, True, True)}\n",
    "\n",
    "            for feature in feature_selection.keys():\n",
    "                #Make a FeatureUnion object with the desired features then fit to train reviews\n",
    "                comb_features = yml.make_featureunion(sent_percent=feature_selection[feature][0], \n",
    "                                                      tf = feature_selection[feature][1], \n",
    "                                                      lda = feature_selection[feature][2])\n",
    "\n",
    "                delta_vect = None\n",
    "                comb_features.fit(sub_train_reviews)\n",
    "                train_features = comb_features.transform(sub_train_reviews)\n",
    "\n",
    "                #Fit LSI model and return number of LSI topics\n",
    "                lsi, topics, dictionary = yml.fit_lsi(sub_train_reviews)\n",
    "                train_lsi = yml.get_lsi_features(sub_train_reviews, lsi, topics, dictionary)\n",
    "\n",
    "                #Stack the LSI and combined features together\n",
    "                train_features = sparse.hstack((train_features, train_lsi))\n",
    "                train_features = train_features.todense()\n",
    "\n",
    "                #fit each model in turn \n",
    "                model_runs = {\"svm\": (True, False, False),\n",
    "                              \"rf\": (False, True, False), \n",
    "                              \"naive_bayes\": (False, False, True)}\n",
    "\n",
    "                for model_run in model_runs.keys():\n",
    "                    clf = yml.fit_model(train_features, train_labels, svm_clf = model_runs[model_run][0], \n",
    "                                    RandomForest = model_runs[model_run][1], \n",
    "                                        nb = model_runs[model_run][2])\n",
    "                    threshold = 0.7\n",
    "                    error = yml.test_user_set(test_set, clf, restaurant_df, user_df, comb_features, \n",
    "                                              threshold, lsi, topics, dictionary, delta_vect)\n",
    "                    test_results[str((feature, model_run))] = (yml.get_log_loss(error), \n",
    "                                                    yml.get_accuracy_score(error), \n",
    "                                                    yml.get_precision_score(error))\n",
    "                \n",
    "    string_keys_dict[str(users.keys()[j])] = test_results\n",
    "            \n",
    "with open('test_results.json', 'wb') as fp:\n",
    "    json.dump(string_keys_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_results = string_keys_dict['n86B7IkbU20AkxlFX_5aew']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "#Make a Recommendation\n",
    "#########################\n",
    "top_results = []\n",
    "#Get feature and model combination that yields the highest precision\n",
    "for key in test_results.keys():\n",
    "    feat_model = make_tuple(key)\n",
    "    if not top_results:\n",
    "        top_results = [(feat_model,test_results[key][2])]\n",
    "    else:\n",
    "        if test_results[key][2] > top_results[0][1]:\n",
    "            top_results.pop()\n",
    "            top_results = [(feat_model, test_results[key][2])]\n",
    "feat_result = top_results[0][0][0]\n",
    "model_result = top_results[0][0][1]\n",
    "\n",
    "for j in tqdm.tqdm(range(155, 157)):\n",
    "    user_df = yml.make_user_df(users[users.keys()[j]])\n",
    "    business_ids = list(set(user_df['biz_id']))\n",
    "\n",
    "    #Create a list of training reviews and training ratings\n",
    "    for rest_id in business_ids:\n",
    "        train_reviews.append((user_df[user_df['biz_id'] == rest_id]['review_text'].iloc[0],\n",
    "                                 user_df[user_df['biz_id'] == rest_id]['rating'].iloc[0]))\n",
    "\n",
    "    #Create an even sample s.t. len(positive_reviews) = len(negative_reviews)\n",
    "    sample_size = min(len([x[1] for x in train_reviews if x[1] < 4]),\n",
    "                          len([x[1] for x in train_reviews if x[1] >= 4]))\n",
    "    \n",
    "    bad_reviews = [x for x in train_reviews if x[1] < 4]\n",
    "    good_reviews = [x for x in train_reviews if x[1] >= 4]\n",
    "    \n",
    "    train_labels = []\n",
    "    sub_train_reviews = []\n",
    "    for L in range(0, int(float(sample_size)/float(2))):\n",
    "        sub_train_reviews.append(bad_reviews[L][0])\n",
    "        sub_train_reviews.append(good_reviews[L][0])\n",
    "        train_labels.append(bad_reviews[L][1])\n",
    "        train_labels.append(good_reviews[L][1])\n",
    "        \n",
    "    #Make the train labels binary\n",
    "    train_labels = [1 if x >=4 else 0 for x in train_labels]\n",
    "    \n",
    "    #Fit LSI model and return number of LSI topics\n",
    "    lsi, topics, dictionary = yml.fit_lsi(sub_train_reviews)\n",
    "\n",
    "    #Make a FeatureUnion object with the desired features then fit to train reviews\n",
    "    feature_selection = {\"sent_tf\":(True, True, False), \n",
    "                         \"sent\": (True,False,False),\n",
    "                         \"tf_lda\": (False,True,True), \n",
    "                         \"all\": (True, True, True)}\n",
    "    top_feature = feature_selection['all']\n",
    "    \n",
    "    comb_features = yml.make_featureunion(sent_percent=top_feature[0], \n",
    "                                          tf = top_feature[1], \n",
    "                                          lda = top_feature[2])\n",
    "        \n",
    "    comb_features.fit(sub_train_reviews)\n",
    "    train_features = comb_features.transform(sub_train_reviews)\n",
    "    train_lsi = yml.get_lsi_features(sub_train_reviews, lsi, topics, dictionary)\n",
    "    train_features = sparse.hstack((train_features, train_lsi))\n",
    "    train_features = train_features.todense()\n",
    "\n",
    "    #Fit LSI model and return number of LSI topics\n",
    "    lsi, topics, dictionary = yml.fit_lsi(sub_train_reviews)\n",
    "        \n",
    "    #Get the top performing model and fit using that model\n",
    "    model_runs = {\"svm\": (True, False, False),\n",
    "                  \"rf\": (False, True, False), \n",
    "                  \"naive_bayes\": (False, False, True)}\n",
    "    top_model = model_runs['svm']\n",
    "    clf = yml.fit_model(train_features, train_labels, svm_clf = top_model[0], \n",
    "                RandomForest = top_model[1], \n",
    "                    nb = top_model[2])\n",
    "\n",
    "    threshold = 0.7\n",
    "    user_results = yml.make_rec(dc_reviews, clf, threshold, comb_features, \n",
    "                                lsi, topics, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################################################################\n",
    "#Collect the results into a list of tuples, then select the top\n",
    "#5 most confident good recs and top 5 most confident bad recs\n",
    "################################################################\n",
    "tuple_results = []\n",
    "for result in user_results:\n",
    "    tuple_results.append((result[1], result[2], result[3]))\n",
    "    \n",
    "#Sort the list of tuples by predicition confidence\n",
    "tuple_results = sorted(tuple_results, key=lambda tup: tup[1])\n",
    "top_5 = tuple_results[-5:]\n",
    "bottom_5 = tuple_results[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'/biz/bar-a-vin-washington', 0.94999999999999996, 1),\n",
       " (u'/biz/ristorante-la-perla-of-washington-washington-3',\n",
       "  0.94999999999999996,\n",
       "  1),\n",
       " (u'/biz/ruths-chris-steak-house-washington', 1.0, 1),\n",
       " (u'/biz/la-jambe-washington', 1.0, 1),\n",
       " (u'/biz/ghibellina-washington', 1.0, 1)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the top 5 restaurants\n",
    "top_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'/biz/daikaya-ramen-shop-washington', 0.0, 0),\n",
       " (u'/biz/moxies-washington', 0.14999999999999999, 0),\n",
       " (u'/biz/cornerstone-cafe-washington', 0.14999999999999999, 0),\n",
       " (u'/biz/sakuramen-washington', 0.20000000000000001, 0),\n",
       " (u'/biz/subbs-washington', 0.25, 0)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the bottom 5 restaurants\n",
    "bottom_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-0ab3001d1287>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#user_df contains all of the user's reviews, with one column of restaurants,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#one column of the user's ratings, and one column with the user's reviews\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0muser_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_user_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"n86B7IkbU20AkxlFX_5aew\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0muser_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/robertsonwang/Desktop/Python/Yelp/yelp-classification/machine_learning/yelp_ml.py\u001b[0m in \u001b[0;36mmake_user_df\u001b[0;34m(user_specific_reviews)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mreview\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muser_specific_reviews\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0muser_reviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m         \u001b[0muser_ratings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stars'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mbusiness_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'business_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers, not str"
     ]
    }
   ],
   "source": [
    "#user_df contains all of the user's reviews, with one column of restaurants,\n",
    "#one column of the user's ratings, and one column with the user's reviews\n",
    "user_df = yml.make_user_df(users[users.keys()[j]])\n",
    "user_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-aaf4f92902c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#View the top words in the LDA representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mno_top_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtf_feature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdisplay_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_feature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_top_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "#View the top words in the LDA representation\n",
    "no_top_words = 10\n",
    "tf_feature_names = vectorizer.get_feature_names()\n",
    "display_topics(lda_fit, tf_feature_names, no_top_words)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
